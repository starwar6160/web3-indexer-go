package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log/slog"
	"math/big"
	"net"
	"net/http"
	"regexp"
	"strings"
	"sync"
	"time"

	"web3-indexer-go/internal/engine"
	"web3-indexer-go/internal/web"

	"github.com/jmoiron/sqlx"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// REST Models
type Block struct {
	ProcessedAt string `db:"processed_at" json:"processed_at"`
	Number      string `db:"number" json:"number"`
	Hash        string `db:"hash" json:"hash"`
	ParentHash  string `db:"parent_hash" json:"parent_hash"`
	Timestamp   string `db:"timestamp" json:"timestamp"`
}

type Transfer struct {
	ID           int    `db:"id" json:"id"`
	BlockNumber  string `db:"block_number" json:"block_number"`
	TxHash       string `db:"tx_hash" json:"tx_hash"`
	LogIndex     int    `db:"log_index" json:"log_index"`
	FromAddress  string `db:"from_address" json:"from_address"`
	ToAddress    string `db:"to_address" json:"to_address"`
	Amount       string `db:"amount" json:"amount"`
	TokenAddress string `db:"token_address" json:"token_address"`
	Symbol       string `db:"symbol" json:"symbol"`      // âœ… ä»£å¸ç¬¦å·
	Type         string `db:"activity_type" json:"type"` // âœ… æ–°å¢ï¼šæ´»åŠ¨ç±»å‹
}

// Server åŒ…è£… HTTP æœåŠ¡
type Server struct {
	db          *sqlx.DB
	wsHub       *web.Hub
	port        string
	title       string
	rpcPool     engine.RPCClient
	lazyManager *engine.LazyManager
	signer      *engine.SignerMachine
	chainID     int64
	mu          sync.RWMutex
}

func NewServer(db *sqlx.DB, wsHub *web.Hub, port, title string) *Server {
	return &Server{
		db:     db,
		wsHub:  wsHub,
		port:   port,
		title:  title,
		signer: engine.NewSignerMachine("Yokohama-Lab-Primary"),
	}
}

// SetDependencies åŠ¨æ€æ³¨å…¥è¿è¡ŒæœŸä¾èµ–
func (s *Server) SetDependencies(db *sqlx.DB, rpcPool engine.RPCClient, lazyManager *engine.LazyManager, chainID int64) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.db = db
	s.rpcPool = rpcPool
	s.lazyManager = lazyManager
	s.chainID = chainID
	slog.Info("ğŸ’‰ API Server dependencies injected")
}

func (s *Server) Start() error {
	mux := http.NewServeMux()

	// é™æ€èµ„æº
	mux.Handle("/static/", web.HandleStatic())

	// API è·¯ç”± (ä½¿ç”¨é—­åŒ…å»¶è¿Ÿè®¿é—®ä¾èµ–)
	mux.HandleFunc("/api/blocks", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		s.mu.RUnlock()
		if db == nil {
			http.Error(w, "System Initializing...", 503)
			return
		}
		handleGetBlocks(w, r, db)
	})

	mux.HandleFunc("/api/transfers", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		s.mu.RUnlock()
		if db == nil {
			http.Error(w, "System Initializing...", 503)
			return
		}
		handleGetTransfers(w, r, db)
	})

	mux.HandleFunc("/api/status", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		rpcPool := s.rpcPool
		lazyManager := s.lazyManager
		chainID := s.chainID
		s.mu.RUnlock()

		if db == nil || rpcPool == nil {
			// è¿”å›æœ€å°åŒ–çš„åˆå§‹åŒ–çŠ¶æ€
			w.Header().Set("Content-Type", "application/json")
			if err := json.NewEncoder(w).Encode(map[string]interface{}{
				"state": "initializing",
				"title": s.title,
				"msg":   "Database or RPC not ready yet",
			}); err != nil {
				slog.Error("failed_to_encode_init_status", "err", err)
			}
			return
		}
		handleGetStatus(w, r, db, rpcPool, lazyManager, chainID, s.signer)
	})

	mux.HandleFunc("/ws", func(w http.ResponseWriter, r *http.Request) {
		s.wsHub.HandleWS(w, r)
	})

	// é¦–é¡µ
	mux.HandleFunc("/", web.RenderDashboard)
	mux.HandleFunc("/security", web.RenderSecurity)

	// Prometheus æŒ‡æ ‡
	mux.Handle("/metrics", promhttp.Handler())

	slog.Info("ğŸŒ Server listening", "port", s.port)
	srv := &http.Server{
		Addr:              ":" + s.port,
		Handler:           VisitorStatsMiddleware(nil, mux),
		ReadHeaderTimeout: 5 * time.Second,
		ReadTimeout:       10 * time.Second,
		WriteTimeout:      10 * time.Second,
		IdleTimeout:       120 * time.Second,
	}
	return srv.ListenAndServe()
}

func handleGetBlocks(w http.ResponseWriter, r *http.Request, db *sqlx.DB) {
	type dbBlock struct {
		ProcessedAt time.Time `db:"processed_at"`
		Number      string    `db:"number"`
		Hash        string    `db:"hash"`
		ParentHash  string    `db:"parent_hash"`
		Timestamp   string    `db:"timestamp"`
	}
	var rawBlocks []dbBlock
	// å¼ºåˆ¶è¦æ±‚å­—æ®µé¡ºåºï¼Œå¹¶ä½¿ç”¨ AS åˆ«åæ¶ˆé™¤æ··æ·†
	err := db.SelectContext(r.Context(), &rawBlocks, `
		SELECT 
			number, 
			hash, 
			parent_hash, 
			timestamp, 
			processed_at 
		FROM blocks 
		ORDER BY number DESC 
		LIMIT 10
	`)
	if err != nil {
		slog.Error("failed_to_get_blocks", "err", err)
		http.Error(w, "Failed to retrieve blocks", 500)
		return
	}

	// æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å­—ç¬¦ä¸² (15:04:05.000)
	blocks := make([]Block, len(rawBlocks))
	for i, b := range rawBlocks {
		blocks[i] = Block{
			Number:      b.Number,
			Hash:        b.Hash,
			ParentHash:  b.ParentHash,
			Timestamp:   b.Timestamp,
			ProcessedAt: b.ProcessedAt.Format("15:04:05.000"), // â³ ç²¾ç¡®åˆ°æ¯«ç§’çš„æ—¶åˆ»
		}
	}

	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(map[string]interface{}{"blocks": blocks}); err != nil {
		slog.Error("failed_to_encode_blocks", "err", err)
	}
}

func handleGetTransfers(w http.ResponseWriter, r *http.Request, db *sqlx.DB) {
	var transfers []Transfer
	err := db.SelectContext(r.Context(), &transfers, "SELECT id, block_number, tx_hash, log_index, from_address, to_address, amount, token_address, symbol, activity_type FROM transfers ORDER BY block_number DESC, log_index DESC LIMIT 10")
	if err != nil {
		slog.Error("failed_to_get_transfers", "err", err)
		http.Error(w, "Failed to retrieve transfers", 500)
		return
	}
	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(map[string]interface{}{"transfers": transfers}); err != nil {
		slog.Error("failed_to_encode_transfers", "err", err)
	}
}

// TrafficAnalyzer å†…å­˜æ»‘åŠ¨çª—å£åˆ†æå™¨ (SRE Anomaly Detection)
type TrafficAnalyzer struct {
	mu        sync.RWMutex
	counts    map[string]int
	threshold float64
	total     int
}

func NewTrafficAnalyzer(threshold float64) *TrafficAnalyzer {
	return &TrafficAnalyzer{
		counts:    make(map[string]int),
		threshold: threshold,
	}
}

func (ta *TrafficAnalyzer) Record(ip string) {
	ta.mu.Lock()
	defer ta.mu.Unlock()
	ta.counts[ip]++
	ta.total++

	// å®šæœŸæ¸…ç†çª—å£ (é˜²æ­¢å†…å­˜æ— é™å¢é•¿ï¼Œæ¯ 2000 æ¬¡è¯·æ±‚é‡ç½®ä¸€æ¬¡)
	if ta.total > 2000 {
		for k := range ta.counts {
			delete(ta.counts, k)
		}
		ta.total = 0
	}
}

func (ta *TrafficAnalyzer) GetAdminIP() string {
	ta.mu.RLock()
	defer ta.mu.RUnlock()
	if ta.total < 100 { // æœ€å°é‡‡æ ·é˜ˆå€¼
		return ""
	}
	for ip, count := range ta.counts {
		if float64(count)/float64(ta.total) > ta.threshold {
			return ip
		}
	}
	return ""
}

var globalAnalyzer = NewTrafficAnalyzer(0.9)

// VisitorStatsMiddleware æ‹¦æˆªæµé‡å¹¶è®°å½•ç‹¬ç«‹è®¿å®¢ (å…·å¤‡åŠ¨æ€å¼‚å¸¸æ£€æµ‹èƒ½åŠ›)
func VisitorStatsMiddleware(db *sqlx.DB, next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		ip := r.Header.Get("X-Forwarded-For")
		if ip == "" {
			ip = r.RemoteAddr
		}

		// æ›´åŠ é²æ£’çš„ IP è§£æï¼Œå¤„ç† IPv4/IPv6 ä»¥åŠç«¯å£å·
		if host, _, err := net.SplitHostPort(ip); err == nil {
			ip = host
		} else {
			// å¦‚æœæ²¡æœ‰ç«¯å£å·ï¼ˆä¾‹å¦‚æ¥è‡ª X-Forwarded-Forï¼‰ï¼ŒSplitHostPort ä¼šæŠ¥é”™ï¼Œç›´æ¥ä½¿ç”¨åŸå€¼
			ip = strings.TrimSpace(ip)
			// å¦‚æœæ˜¯å¤šä¸ª IPï¼ˆX-Forwarded-For: client, proxy1, proxy2ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ª
			if idx := strings.Index(ip, ","); idx != -1 {
				ip = strings.TrimSpace(ip[:idx])
			}
		}

		ua := r.UserAgent()

		// 1. æ›´æ–°åˆ†æå™¨æ•°æ®
		globalAnalyzer.Record(ip)

		// 2. åŠ¨æ€åˆ¤å®šï¼šæ’é™¤å æ¯”è¿‡é«˜çš„â€œå¼‚å¸¸ IPâ€ï¼ˆé€šå¸¸æ˜¯ç®¡ç†å‘˜è°ƒè¯•æˆ–å‹æµ‹æºï¼‰
		if ip == globalAnalyzer.GetAdminIP() || ip == "127.0.0.1" {
			next.ServeHTTP(w, r)
			return
		}

		// 3. åˆ¤å®šæ˜¯å¦ä¸ºâ€œäººç±»æµè§ˆå™¨â€æµé‡
		isBot := regexp.MustCompile(`(?i)(bot|crawler|spider|curl|wget|python|postman)`).MatchString(ua)
		isBrowser := strings.Contains(ua, "Mozilla")

		if isBrowser && !isBot && r.Method == http.MethodGet {
			// 4. å¼‚æ­¥æŒä¹…åŒ– (ä»…å½“ DB å·²å°±ç»ª)
			if db != nil {
				go logVisitor(db, ip, ua, r.URL.Path)
			}
		}

		next.ServeHTTP(w, r)
	})
}

func logVisitor(db *sqlx.DB, ip, ua, path string) {
	metadata := map[string]interface{}{
		"path":       path,
		"recorded_v": "v1",
	}
	metaJSON, err := json.Marshal(metadata)
	if err != nil {
		slog.Error("failed_to_marshal_metadata", "err", err)
		return
	}

	// Retry mechanism for database operations
	maxRetries := 3
	for attempt := 0; attempt < maxRetries; attempt++ {
		_, err := db.Exec("INSERT INTO visitor_stats (ip_address, user_agent, metadata) VALUES ($1, $2, $3)",
			ip, ua, metaJSON)
		if err == nil {
			// Success, exit the retry loop
			return
		}

		// Log the error but don't spam if it's a connection issue
		if attempt < maxRetries-1 {
			slog.Warn("failed_to_log_visitor_retrying", "err", err, "ip", ip, "attempt", attempt+1)
			time.Sleep(time.Millisecond * 100 * time.Duration(attempt+1)) // Exponential backoff
		} else {
			// Final attempt failed, log the error
			slog.Error("failed_to_log_visitor_permanent", "err", err, "ip", ip, "attempts", maxRetries)
		}
	}
}

func handleGetStatus(w http.ResponseWriter, r *http.Request, db *sqlx.DB, rpcPool engine.RPCClient, lazyManager *engine.LazyManager, _ int64, signer *engine.SignerMachine) {
	// Trigger indexing if cooldown period has passed
	if lazyManager != nil {
		slog.Debug("ğŸš€ API access detected, triggering lazy manager")
		lazyManager.Trigger()
	}

	ctx := r.Context()
	// 1. è·å–é“¾ä¸Šé«˜åº¦ä¸åŒæ­¥é«˜åº¦
	latestChainBlock, err := rpcPool.GetLatestBlockNumber(ctx)
	if err != nil {
		slog.Error("failed_to_get_latest_block", "err", err)
	}
	latestIndexedBlock := getLatestIndexedBlock(ctx, db)

	// 2. è·å–ç»Ÿè®¡æ•°æ®
	totalBlocks := getCount(ctx, db, "SELECT COUNT(*) FROM blocks")
	totalTransfers := getCount(ctx, db, "SELECT COUNT(*) FROM transfers")
	totalVisitors := getCount(ctx, db, "SELECT COUNT(DISTINCT ip_address) FROM visitor_stats")

	// 3. è®¡ç®—å»¶è¿Ÿä¸çŠ¶æ€
	latestChainInt64 := int64(0)
	if latestChainBlock != nil {
		latestChainInt64 = latestChainBlock.Int64()
	}
	latestIndexedBlockInt64 := parseBlockNumber(latestIndexedBlock)

	syncLag := latestChainInt64 - latestIndexedBlockInt64
	if syncLag < 0 {
		syncLag = 0
	}

	e2eLatencyDisplay, e2eLatencySeconds := calculateLatency(ctx, db, latestChainInt64, latestIndexedBlockInt64, latestIndexedBlock)

	// 4. ç»„è£…å“åº”
	adminIP := globalAnalyzer.GetAdminIP()
	if adminIP != "" && adminIP != "127.0.0.1" {
		adminIP = "Protected-Internal-Node"
	}

	tps := calculateTPS(ctx, db)
	isCatchingUp := syncLag > 10
	if isCatchingUp {
		tps = 0.0
	}

	status := map[string]interface{}{
		"version":            "v2.2.0-intelligence-engine",
		"state":              "active",
		"latest_block":       fmt.Sprintf("%d", latestChainInt64),
		"latest_indexed":     latestIndexedBlock,
		"sync_lag":           syncLag,
		"total_blocks":       totalBlocks,
		"total_transfers":    totalTransfers,
		"total_visitors":     totalVisitors,
		"tps":                tps,
		"is_catching_up":     isCatchingUp,
		"bps":                currentBPS.Load(),
		"is_healthy":         rpcPool.GetHealthyNodeCount() > 0,
		"self_healing_count": selfHealingEvents.Load(),
		"admin_ip":           adminIP,
		"rpc_nodes": map[string]int{
			"healthy": rpcPool.GetHealthyNodeCount(),
			"total":   rpcPool.GetTotalNodeCount(),
		},
		"e2e_latency_seconds": e2eLatencySeconds,
		"e2e_latency_display": e2eLatencyDisplay,
	}

	if lazyManager != nil {
		status["lazy_indexer"] = lazyManager.GetStatus()
	}

	// ğŸ›¡ï¸ ç¡®å®šæ€§å®‰å…¨ç­¾å
	if signer != nil {
		if signed, err := signer.Sign("status", status); err == nil {
			w.Header().Set("X-Payload-Signature", signed.Signature)
			w.Header().Set("X-Signer-ID", signed.SignerID)
			w.Header().Set("X-Public-Key", signed.PubKey)
		}
	}

	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(status); err != nil {
		slog.Error("failed_to_encode_status", "err", err)
	}
}

func getLatestIndexedBlock(ctx context.Context, db *sqlx.DB) string {
	var latest string
	if err := db.GetContext(ctx, &latest, "SELECT COALESCE(MAX(number), '0') FROM blocks"); err != nil {
		return "0"
	}
	return latest
}

func getCount(ctx context.Context, db *sqlx.DB, query string) int64 {
	var count int64
	if err := db.GetContext(ctx, &count, query); err != nil {
		return 0
	}
	return count
}

func parseBlockNumber(s string) int64 {
	if s == "" || s == "0" {
		return 0
	}
	if parsed, ok := new(big.Int).SetString(s, 10); ok {
		return parsed.Int64()
	}
	return 0
}

func calculateLatency(ctx context.Context, db *sqlx.DB, latestChain, latestIndexed int64, latestIndexedStr string) (string, float64) {
	if latestChain <= 0 || latestIndexed <= 0 {
		return "0s", 0
	}

	syncLag := latestChain - latestIndexed
	if syncLag < 0 {
		syncLag = 0
	}

	// ğŸš€ å·¥ä¸šçº§é˜²å¾¡ï¼šå¦‚æœè½åå¤ªå¤šï¼ˆ>100å—ï¼‰ï¼Œç›´æ¥æŒ‰åŒºå—å¹³å‡æ—¶é—´ä¼°ç®—
	if syncLag > 100 {
		estLatency := float64(syncLag) * 12
		return fmt.Sprintf("Catching up... (%d blocks behind)", syncLag), estLatency
	}

	// å®æ—¶/å°å»¶è¿Ÿæ¨¡å¼ï¼šå°è¯•ä»æ•°æ®åº“è·å–æœ€æ–°åŒºå—çš„å¤„ç†æ—¶é—´
	var processedAt time.Time
	err := db.GetContext(ctx, &processedAt, "SELECT processed_at FROM blocks WHERE number = $1", latestIndexedStr)

	if err == nil && !processedAt.IsZero() {
		latency := time.Since(processedAt).Seconds()
		// ğŸ›¡ï¸ å¼‚å¸¸é˜²å¾¡ï¼šå¦‚æœè®¡ç®—å‡ºçš„å»¶è¿Ÿè¶…è¿‡äº†ç†è®ºä¸Šé™ï¼ˆæ¯”å¦‚ Anvil é‡å¯å¯¼è‡´çš„å·¨å¤§æ—¶é—´å·®ï¼‰ï¼Œè¿›è¡Œå¹³æ»‘å¤„ç†
		maxExpectedLatency := float64(syncLag+1) * 15 // å…è®¸ä¸€å®šçš„ Buffer
		if latency > maxExpectedLatency && syncLag < 5 {
			// å¦‚æœåªæœ‰å‡ ä¸ªå—çš„å»¶è¿Ÿï¼Œä½†æ—¶é—´å·®å·¨å¤§ï¼Œè¯´æ˜æ˜¯ç¯å¢ƒé‡ç½®
			latency = float64(syncLag) * 2.0 // ç»™ä¸€ä¸ªè¾ƒå°çš„å‡å®šå€¼
		}

		if latency < 0 {
			latency = 0
		}
		return fmt.Sprintf("%.2fs", latency), latency
	}

	// Fallback: çº¯ç†è®ºä¼°ç®—
	fallbackLatency := float64(syncLag) * 12
	return fmt.Sprintf("%.2fs", fallbackLatency), fallbackLatency
}

// calculateTPS è®¡ç®— Transactions Per Second
func calculateTPS(ctx context.Context, db *sqlx.DB) float64 {
	// ğŸš€ å·¥ä¸šçº§å¯¹é½ï¼šç›´æ¥ä» Metrics çš„ 5s æ»‘åŠ¨çª—å£è·å–
	return engine.GetMetrics().GetWindowTPS()
}

// getLazyIndexerStatus returns a human-readable status for the lazy indexer
func getLazyIndexerStatus(isActive bool) string {
	if isActive {
		return "â— æ­£åœ¨è¿½èµ¶ä¸­ (Catching up...)"
	}
	return "â— èŠ‚èƒ½æ¨¡å¼ (Lazy Mode)"
}
