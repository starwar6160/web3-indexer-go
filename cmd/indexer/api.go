package main

import (
	"encoding/json"
	"fmt"
	"log/slog"
	"math"
	"math/big"
	"net"
	"net/http"
	"regexp"
	"strings"
	"sync"
	"time"

	"web3-indexer-go/internal/engine"
	"web3-indexer-go/internal/web"

	"github.com/jmoiron/sqlx"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// REST Models
type Block struct {
	ProcessedAt string `db:"processed_at" json:"processed_at"`
	Number      string `db:"number" json:"number"`
	Hash        string `db:"hash" json:"hash"`
	ParentHash  string `db:"parent_hash" json:"parent_hash"`
	Timestamp   string `db:"timestamp" json:"timestamp"`
}

type Transfer struct {
	ID           int    `db:"id" json:"id"`
	BlockNumber  string `db:"block_number" json:"block_number"`
	TxHash       string `db:"tx_hash" json:"tx_hash"`
	LogIndex     int    `db:"log_index" json:"log_index"`
	FromAddress  string `db:"from_address" json:"from_address"`
	ToAddress    string `db:"to_address" json:"to_address"`
	Amount       string `db:"amount" json:"amount"`
	TokenAddress string `db:"token_address" json:"token_address"`
}

// Server åŒ…è£… HTTP æœåŠ¡
type Server struct {
	db          *sqlx.DB
	wsHub       *web.Hub
	port        string
	title       string
	rpcPool     engine.RPCClient
	lazyManager *engine.LazyManager
	chainID     int64
	mu          sync.RWMutex
}

func NewServer(db *sqlx.DB, wsHub *web.Hub, port, title string) *Server {
	return &Server{
		db:    db,
		wsHub: wsHub,
		port:  port,
		title: title,
	}
}

// SetDependencies åŠ¨æ€æ³¨å…¥è¿è¡ŒæœŸä¾èµ–
func (s *Server) SetDependencies(db *sqlx.DB, rpcPool engine.RPCClient, lazyManager *engine.LazyManager, chainID int64) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.db = db
	s.rpcPool = rpcPool
	s.lazyManager = lazyManager
	s.chainID = chainID
	slog.Info("ğŸ’‰ API Server dependencies injected")
}

func (s *Server) Start() error {
	mux := http.NewServeMux()

	// é™æ€èµ„æº
	mux.Handle("/static/", web.HandleStatic())

	// API è·¯ç”± (ä½¿ç”¨é—­åŒ…å»¶è¿Ÿè®¿é—®ä¾èµ–)
	mux.HandleFunc("/api/blocks", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		s.mu.RUnlock()
		if db == nil {
			http.Error(w, "System Initializing...", 503)
			return
		}
		handleGetBlocks(w, r, db)
	})

	mux.HandleFunc("/api/transfers", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		s.mu.RUnlock()
		if db == nil {
			http.Error(w, "System Initializing...", 503)
			return
		}
		handleGetTransfers(w, r, db)
	})

	mux.HandleFunc("/api/status", func(w http.ResponseWriter, r *http.Request) {
		s.mu.RLock()
		db := s.db
		rpcPool := s.rpcPool
		lazyManager := s.lazyManager
		chainID := s.chainID
		s.mu.RUnlock()

		if db == nil || rpcPool == nil {
			// è¿”å›æœ€å°åŒ–çš„åˆå§‹åŒ–çŠ¶æ€
			w.Header().Set("Content-Type", "application/json")
			json.NewEncoder(w).Encode(map[string]interface{}{
				"state": "initializing",
				"title": s.title,
				"msg":   "Database or RPC not ready yet",
			})
			return
		}
		handleGetStatus(w, r, db, rpcPool, lazyManager, chainID)
	})

	mux.HandleFunc("/ws", func(w http.ResponseWriter, r *http.Request) {
		s.wsHub.HandleWS(w, r)
	})

	// é¦–é¡µ
	mux.HandleFunc("/", web.RenderDashboard)
	mux.HandleFunc("/security", web.RenderSecurity)

	// Prometheus æŒ‡æ ‡
	mux.Handle("/metrics", promhttp.Handler())

	slog.Info("ğŸŒ Server listening", "port", s.port)
	return http.ListenAndServe(":"+s.port, VisitorStatsMiddleware(nil, mux))
}

func handleGetBlocks(w http.ResponseWriter, r *http.Request, db *sqlx.DB) {
	type dbBlock struct {
		ProcessedAt time.Time `db:"processed_at"`
		Number      string    `db:"number"`
		Hash        string    `db:"hash"`
		ParentHash  string    `db:"parent_hash"`
		Timestamp   string    `db:"timestamp"`
	}
	var rawBlocks []dbBlock
	// å¼ºåˆ¶è¦æ±‚å­—æ®µé¡ºåºï¼Œå¹¶ä½¿ç”¨ AS åˆ«åæ¶ˆé™¤æ··æ·†
	err := db.SelectContext(r.Context(), &rawBlocks, `
		SELECT 
			number, 
			hash, 
			parent_hash, 
			timestamp, 
			processed_at 
		FROM blocks 
		ORDER BY number DESC 
		LIMIT 10
	`)
	if err != nil {
		slog.Error("failed_to_get_blocks", "err", err)
		http.Error(w, "Failed to retrieve blocks", 500)
		return
	}

	// æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å­—ç¬¦ä¸² (15:04:05.000)
	blocks := make([]Block, len(rawBlocks))
	for i, b := range rawBlocks {
		blocks[i] = Block{
			Number:      b.Number,
			Hash:        b.Hash,
			ParentHash:  b.ParentHash,
			Timestamp:   b.Timestamp,
			ProcessedAt: b.ProcessedAt.Format("15:04:05.000"), // â³ ç²¾ç¡®åˆ°æ¯«ç§’çš„æ—¶åˆ»
		}
	}

	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(map[string]interface{}{"blocks": blocks}); err != nil {
		slog.Error("failed_to_encode_blocks", "err", err)
	}
}

func handleGetTransfers(w http.ResponseWriter, r *http.Request, db *sqlx.DB) {
	var transfers []Transfer
	err := db.SelectContext(r.Context(), &transfers, "SELECT id, block_number, tx_hash, log_index, from_address, to_address, amount, token_address FROM transfers ORDER BY block_number DESC LIMIT 10")
	if err != nil {
		slog.Error("failed_to_get_transfers", "err", err)
		http.Error(w, "Failed to retrieve transfers", 500)
		return
	}
	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(map[string]interface{}{"transfers": transfers}); err != nil {
		slog.Error("failed_to_encode_transfers", "err", err)
	}
}

// TrafficAnalyzer å†…å­˜æ»‘åŠ¨çª—å£åˆ†æå™¨ (SRE Anomaly Detection)
type TrafficAnalyzer struct {
	mu        sync.RWMutex
	counts    map[string]int
	threshold float64
	total     int
}

func NewTrafficAnalyzer(threshold float64) *TrafficAnalyzer {
	return &TrafficAnalyzer{
		counts:    make(map[string]int),
		threshold: threshold,
	}
}

func (ta *TrafficAnalyzer) Record(ip string) {
	ta.mu.Lock()
	defer ta.mu.Unlock()
	ta.counts[ip]++
	ta.total++

	// å®šæœŸæ¸…ç†çª—å£ (é˜²æ­¢å†…å­˜æ— é™å¢é•¿ï¼Œæ¯ 2000 æ¬¡è¯·æ±‚é‡ç½®ä¸€æ¬¡)
	if ta.total > 2000 {
		for k := range ta.counts {
			delete(ta.counts, k)
		}
		ta.total = 0
	}
}

func (ta *TrafficAnalyzer) GetAdminIP() string {
	ta.mu.RLock()
	defer ta.mu.RUnlock()
	if ta.total < 100 { // æœ€å°é‡‡æ ·é˜ˆå€¼
		return ""
	}
	for ip, count := range ta.counts {
		if float64(count)/float64(ta.total) > ta.threshold {
			return ip
		}
	}
	return ""
}

var globalAnalyzer = NewTrafficAnalyzer(0.9)

// VisitorStatsMiddleware æ‹¦æˆªæµé‡å¹¶è®°å½•ç‹¬ç«‹è®¿å®¢ (å…·å¤‡åŠ¨æ€å¼‚å¸¸æ£€æµ‹èƒ½åŠ›)
func VisitorStatsMiddleware(db *sqlx.DB, next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		ip := r.Header.Get("X-Forwarded-For")
		if ip == "" {
			ip = r.RemoteAddr
		}

		// æ›´åŠ é²æ£’çš„ IP è§£æï¼Œå¤„ç† IPv4/IPv6 ä»¥åŠç«¯å£å·
		if host, _, err := net.SplitHostPort(ip); err == nil {
			ip = host
		} else {
			// å¦‚æœæ²¡æœ‰ç«¯å£å·ï¼ˆä¾‹å¦‚æ¥è‡ª X-Forwarded-Forï¼‰ï¼ŒSplitHostPort ä¼šæŠ¥é”™ï¼Œç›´æ¥ä½¿ç”¨åŸå€¼
			ip = strings.TrimSpace(ip)
			// å¦‚æœæ˜¯å¤šä¸ª IPï¼ˆX-Forwarded-For: client, proxy1, proxy2ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ª
			if idx := strings.Index(ip, ","); idx != -1 {
				ip = strings.TrimSpace(ip[:idx])
			}
		}

		ua := r.UserAgent()

		// 1. æ›´æ–°åˆ†æå™¨æ•°æ®
		globalAnalyzer.Record(ip)

		// 2. åŠ¨æ€åˆ¤å®šï¼šæ’é™¤å æ¯”è¿‡é«˜çš„â€œå¼‚å¸¸ IPâ€ï¼ˆé€šå¸¸æ˜¯ç®¡ç†å‘˜è°ƒè¯•æˆ–å‹æµ‹æºï¼‰
		if ip == globalAnalyzer.GetAdminIP() || ip == "127.0.0.1" {
			next.ServeHTTP(w, r)
			return
		}

		// 3. åˆ¤å®šæ˜¯å¦ä¸ºâ€œäººç±»æµè§ˆå™¨â€æµé‡
		isBot := regexp.MustCompile(`(?i)(bot|crawler|spider|curl|wget|python|postman)`).MatchString(ua)
		isBrowser := strings.Contains(ua, "Mozilla")

		if isBrowser && !isBot && r.Method == http.MethodGet {
			// 4. å¼‚æ­¥æŒä¹…åŒ– (ä»…å½“ DB å·²å°±ç»ª)
			if db != nil {
				go logVisitor(db, ip, ua, r.URL.Path)
			}
		}

		next.ServeHTTP(w, r)
	})
}

func logVisitor(db *sqlx.DB, ip, ua, path string) {
	metadata := map[string]interface{}{
		"path":       path,
		"recorded_v": "v1",
	}
	metaJSON, err := json.Marshal(metadata)
	if err != nil {
		slog.Error("failed_to_marshal_metadata", "err", err)
		return
	}

	// Retry mechanism for database operations
	maxRetries := 3
	for attempt := 0; attempt < maxRetries; attempt++ {
		_, err := db.Exec("INSERT INTO visitor_stats (ip_address, user_agent, metadata) VALUES ($1, $2, $3)",
			ip, ua, metaJSON)
		if err == nil {
			// Success, exit the retry loop
			return
		}

		// Log the error but don't spam if it's a connection issue
		if attempt < maxRetries-1 {
			slog.Warn("failed_to_log_visitor_retrying", "err", err, "ip", ip, "attempt", attempt+1)
			time.Sleep(time.Millisecond * 100 * time.Duration(attempt+1)) // Exponential backoff
		} else {
			// Final attempt failed, log the error
			slog.Error("failed_to_log_visitor_permanent", "err", err, "ip", ip, "attempts", maxRetries)
		}
	}
}

func handleGetStatus(w http.ResponseWriter, r *http.Request, db *sqlx.DB, rpcPool engine.RPCClient, lazyManager *engine.LazyManager, chainID int64) {
	// Trigger indexing if cooldown period has passed
	if lazyManager != nil {
		lazyManager.Trigger()
	}

	// 1. å°è¯•å®æ—¶è·å–é“¾å¤´
	latestChainBlock, err := rpcPool.GetLatestBlockNumber(r.Context())

	// 2. ç¼“å­˜é™çº§é€»è¾‘ï¼šå¦‚æœ RPC å¤±è´¥ï¼ˆå¦‚é™æµï¼‰ï¼Œä»æ•°æ®åº“è¯»å– Heartbeat è®°å½•
	latestBlockStr := "0"
	var latestChainInt64 int64
	if err == nil && latestChainBlock != nil {
		latestChainInt64 = latestChainBlock.Int64()
		latestBlockStr = latestChainBlock.String()
	} else {
		// ä» sync_checkpoints è¯»å–å¿ƒè·³ç¼“å­˜ (åŠ¨æ€æ ¹æ® chainID)
		var cachedBlock string
		err = db.GetContext(r.Context(), &cachedBlock, "SELECT last_synced_block FROM sync_checkpoints WHERE chain_id = $1", chainID)
		if err == nil && cachedBlock != "" {
			latestBlockStr = cachedBlock
			if val, ok := new(big.Int).SetString(cachedBlock, 10); ok {
				latestChainInt64 = val.Int64()
			}
			slog.Debug("using_cached_chain_head", "height", latestBlockStr, "chain_id", chainID)
		}
	}

	var latestIndexedBlock string
	err = db.GetContext(r.Context(), &latestIndexedBlock, "SELECT COALESCE(MAX(number), '0') FROM blocks")
	if err != nil {
		slog.Error("failed_to_get_latest_indexed_block", "err", err)
		latestIndexedBlock = "0"
	}

	var totalBlocks, totalTransfers int64
	err = db.GetContext(r.Context(), &totalBlocks, "SELECT COUNT(*) FROM blocks")
	if err != nil {
		slog.Error("failed_to_get_total_blocks", "err", err)
		totalBlocks = 0
	}

	err = db.GetContext(r.Context(), &totalTransfers, "SELECT COUNT(*) FROM transfers")
	if err != nil {
		slog.Error("failed_to_get_total_transfers", "err", err)
		totalTransfers = 0
	}

	var totalVisitors int64
	err = db.GetContext(r.Context(), &totalVisitors, "SELECT COUNT(DISTINCT ip_address) FROM visitor_stats")
	if err != nil {
		slog.Error("failed_to_get_total_visitors", "err", err)
		totalVisitors = 0
	}

	latestIndexedBlockInt64 := int64(0)
	if latestIndexedBlock != "" && latestIndexedBlock != "0" {
		if parsed, ok := new(big.Int).SetString(latestIndexedBlock, 10); ok {
			latestIndexedBlockInt64 = parsed.Int64()
		}
	}

	var syncLag int64
	if latestChainInt64 > 0 {
		// ä¿®å¤ï¼šä½¿ç”¨ç¼“å­˜æˆ–å®æ—¶çš„é“¾å¤´é«˜åº¦è¿›è¡Œè®¡ç®—
		syncLag = latestChainInt64 - latestIndexedBlockInt64
		if syncLag < 0 {
			syncLag = 0
		}
	}

	// è®¡ç®— E2E Latencyï¼ˆç§’ï¼‰
	var e2eLatencySeconds float64
	var e2eLatencyDisplay string
	if latestChainInt64 > 0 && latestIndexedBlockInt64 > 0 {
		// ä¼°ç®—é€»è¾‘
		syncLag := latestChainInt64 - latestIndexedBlockInt64
		if syncLag < 0 {
			syncLag = 0
		}

		rawLatency := float64(syncLag) * 12 // Sepolia å¹³å‡å‡ºå—æ—¶é—´

		if syncLag > 100 {
			// å¤§è§„æ¨¡è¿½èµ¶æ¨¡å¼ï¼šæ˜¾ç¤ºå‰©ä½™å—æ•°
			e2eLatencySeconds = rawLatency
			e2eLatencyDisplay = fmt.Sprintf("Catching up... (%d blocks behind)", syncLag)
		} else {
			// å®æ—¶/å°å»¶è¿Ÿæ¨¡å¼ï¼šè®¡ç®—å¤„ç†å»¶è¿Ÿ
			var processedAt time.Time
			err = db.GetContext(r.Context(), &processedAt,
				"SELECT processed_at FROM blocks WHERE number = $1", latestIndexedBlock)

			if err == nil && !processedAt.IsZero() {
				actualLatency := time.Since(processedAt).Seconds()
				e2eLatencySeconds = actualLatency
				e2eLatencyDisplay = fmt.Sprintf("%.2fs", actualLatency)
			} else {
				e2eLatencySeconds = rawLatency
				e2eLatencyDisplay = fmt.Sprintf("%.2fs", rawLatency)
			}
		}
	}

	adminIP := globalAnalyzer.GetAdminIP()
	if adminIP != "" && adminIP != "127.0.0.1" {
		// éšç§é˜²å¾¡ï¼šæŠ¹é™¤çœŸå® IPï¼Œæ›¿æ¢ä¸ºå›ºå®šå ä½ç¬¦
		adminIP = "Protected-Internal-Node"
	}

	// è®¡ç®— TPSï¼ˆè¿½èµ¶æ¨¡å¼ä¸‹æ˜¾ç¤ºä¸º 0ï¼‰
	tps := calculateTPS(totalTransfers, totalBlocks)
	isCatchingUp := syncLag > 10 // è¿½èµ¶æ¨¡å¼é˜ˆå€¼ï¼š10 ä¸ªå—
	if isCatchingUp {
		tps = 0.0 // è¿½èµ¶æ¨¡å¼ä¸‹ä¸æ˜¾ç¤ºå®æ—¶ TPSï¼Œé¿å…è¯¯å¯¼
	}

	status := map[string]interface{}{
		"state":              "active",
		"latest_block":       latestBlockStr,
		"latest_indexed":     latestIndexedBlock,
		"sync_lag":           syncLag,
		"total_blocks":       totalBlocks,
		"total_transfers":    totalTransfers,
		"total_visitors":     totalVisitors,
		"tps":                tps,          // è¿½èµ¶æ¨¡å¼ä¸‹æ˜¾ç¤ºä¸º 0
		"is_catching_up":     isCatchingUp, // æ–°å¢ï¼šæ˜¯å¦åœ¨è¿½èµ¶æ¨¡å¼
		"bps":                currentBPS.Load(),
		"is_healthy":         rpcPool.GetHealthyNodeCount() > 0,
		"self_healing_count": selfHealingEvents.Load(),
		"admin_ip":           adminIP,
		"rpc_nodes": map[string]int{
			"healthy": rpcPool.GetHealthyNodeCount(),
			"total":   rpcPool.GetTotalNodeCount(),
		},
		// E2E Latencyï¼ˆå¸¦ä¸Šé™æ£€æµ‹å’Œå‹å¥½æ˜¾ç¤ºï¼‰
		"e2e_latency_seconds": e2eLatencySeconds,
		"e2e_latency_display": e2eLatencyDisplay,
	}

	// Add lazy indexer status if available
	if lazyManager != nil {
		lazyStatus := lazyManager.GetStatus()
		status["lazy_indexer"] = lazyStatus
	}

	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(status); err != nil {
		slog.Error("failed_to_encode_status", "err", err)
	}
}

// calculateTPS è®¡ç®— Transactions Per Secondï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
// ä¿ç•™ 2 ä½å°æ•°ï¼Œé¿å…é•¿æµ®ç‚¹æ•°æ˜¾ç¤º
func calculateTPS(totalTransfers, totalBlocks int64) float64 {
	if totalBlocks == 0 {
		return 0.0
	}
	// ç®€åŒ–è®¡ç®—ï¼šå¹³å‡æ¯ä¸ªåŒºå—çš„è½¬è´¦æ•° / 12 ç§’ï¼ˆSepolia å‡ºå—æ—¶é—´ï¼‰
	// æ³¨æ„ï¼šè¿™æ˜¯å†å²å¹³å‡å€¼ï¼Œä¸æ˜¯å®æ—¶é€Ÿç‡
	avgTransfersPerBlock := float64(totalTransfers) / float64(totalBlocks)
	rawTPS := avgTransfersPerBlock / 12.0

	// ä¿ç•™ 2 ä½å°æ•°ï¼ˆå››èˆäº”å…¥ï¼‰
	return math.Round(rawTPS*100) / 100
}

// getLazyIndexerStatus returns a human-readable status for the lazy indexer
func getLazyIndexerStatus(isActive bool) string {
	if isActive {
		return "â— æ­£åœ¨è¿½èµ¶ä¸­ (Catching up...)"
	}
	return "â— èŠ‚èƒ½æ¨¡å¼ (Lazy Mode)"
}
