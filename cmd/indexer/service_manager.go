package main

import (
	"context"
	"log/slog"
	"math/big"
	"time"

	"web3-indexer-go/internal/engine"

	"github.com/jmoiron/sqlx"
)

// ServiceManager è´Ÿè´£åè°ƒæ‰€æœ‰åº•å±‚ç»„ä»¶
type ServiceManager struct {
	db         *sqlx.DB
	rpcPool    engine.RPCClient
	fetcher    *engine.Fetcher
	Processor  *engine.Processor
	reconciler *engine.Reconciler
	chainID    int64
}

func NewServiceManager(db *sqlx.DB, rpcPool engine.RPCClient, chainID int64, retryQueueSize int, rps, burst, concurrency int, enableSimulator bool, networkMode string, enableRecording bool, recordingPath string) *ServiceManager {
	// âœ¨ ä½¿ç”¨å·¥ä¸šçº§é™æµå™¨åˆ›å»º Fetcher
	fetcher := engine.NewFetcherWithLimiter(rpcPool, concurrency, rps, burst)
	processor := engine.NewProcessor(db, rpcPool, retryQueueSize, chainID, enableSimulator, networkMode)

	// ğŸš€ åˆå§‹åŒ–ç‰©ç†åˆ†å‘ Sink
	if enableRecording && recordingPath != "" {
		if lz4Sink, err := engine.NewLz4Sink(recordingPath); err == nil {
			processor.SetSink(lz4Sink)
			engine.Logger.Info("ğŸ™ï¸ [Recorder] LZ4 Recording ACTIVE", "path", recordingPath)
		} else {
			engine.Logger.Error("failed_to_init_lz4_sink", "err", err)
		}
	}

	reconciler := engine.NewReconciler(db, rpcPool, engine.GetMetrics())

	return &ServiceManager{
		db:         db,
		rpcPool:    rpcPool,
		fetcher:    fetcher,
		Processor:  processor,
		reconciler: reconciler,
		chainID:    chainID,
	}
}

// GetStartBlock å°è£…è‡ªæ„ˆé€»è¾‘
func (sm *ServiceManager) GetStartBlock(ctx context.Context, forceFrom string, resetDB bool) (*big.Int, error) {
	return getStartBlockFromCheckpoint(ctx, sm.db, sm.rpcPool, sm.chainID, forceFrom, resetDB)
}

// StartTailFollow å¯åŠ¨æŒç»­è¿½è¸ª
func (sm *ServiceManager) StartTailFollow(ctx context.Context, startBlock *big.Int) {
	slog.Info("ğŸ¬ [StartTailFollow] Function called", "start_block", startBlock.String())

	// ğŸš€ å·¥ä¸šçº§ä¼˜åŒ–ï¼šGap Check (è‡ªåŠ¨è¡¥æ´)
	// æ£€æŸ¥æ•°æ®åº“ä¸­å·²æœ‰çš„æœ€å¤§åŒºå—å·ï¼Œçœ‹æ˜¯å¦ä¸æœ¬æ¬¡ startBlock å­˜åœ¨æ–­å±‚
	var maxInDB int64
	err := sm.db.GetContext(ctx, &maxInDB, "SELECT COALESCE(MAX(number), 0) FROM blocks")
	if err == nil && maxInDB > 0 {
		startNum := startBlock.Int64()
		if startNum > maxInDB+1 {
			gapSize := startNum - (maxInDB + 1)
			engine.Logger.Info("ğŸ§© Gap detected! Initiating catch-up sync",
				"last_in_db", maxInDB,
				"start_at", startNum,
				"gap_blocks", gapSize)

			// å¯åŠ¨åå°åç¨‹å›å¡« Gapï¼Œä¸é˜»å¡ä¸» Tail æµç¨‹
			go func() {
				catchupCtx := context.Background()
				if err := sm.fetcher.Schedule(catchupCtx, big.NewInt(maxInDB+1), big.NewInt(startNum-1)); err != nil {
					engine.Logger.Error("failed_to_schedule_catchup", "err", err)
				}
			}()
		}
	}

	// å¯åŠ¨åå°æŒ‡æ ‡ä¸ŠæŠ¥
	go sm.startMetricsReporter(ctx)
	continuousTailFollow(ctx, sm.fetcher, sm.rpcPool, startBlock)
}

// startMetricsReporter å®šæœŸä¸ŠæŠ¥ç³»ç»ŸæŒ‡æ ‡åˆ° Prometheus
func (sm *ServiceManager) startMetricsReporter(ctx context.Context) {
	ticker := time.NewTicker(15 * time.Second)
	defer ticker.Stop()

	metrics := engine.GetMetrics()
	metrics.RecordStartTime()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			// ä¸ŠæŠ¥æ•°æ®åº“è¿æ¥æ± çŠ¶æ€
			stats := sm.db.Stats()
			metrics.UpdateDBConnections(stats.OpenConnections)

			// ğŸš€ å­˜å‚¨ç©ºé—´ç›‘æ§
			if free, err := engine.CheckStorageSpace("."); err == nil {
				metrics.UpdateDiskFree(free)
			}
		}
	}
}
