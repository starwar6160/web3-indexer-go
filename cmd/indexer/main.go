package main

import (
	"context"
	"database/sql"
	"flag"
	"fmt"
	"log/slog"
	"math/big"
	"net/http"
	"os"
	"os/signal"
	"sync"
	"sync/atomic"
	"syscall"
	"time"

	"web3-indexer-go/internal/config"
	"web3-indexer-go/internal/database"
	"web3-indexer-go/internal/engine"
	"web3-indexer-go/internal/recovery"
	"web3-indexer-go/internal/web"

	networkpkg "web3-indexer-go/pkg/network"

	"github.com/ethereum/go-ethereum/common"
	"github.com/ethereum/go-ethereum/ethclient"

	_ "github.com/jackc/pgx/v5/stdlib"
	"github.com/jmoiron/sqlx"
)

// DBWrapper wraps sqlx.DB to match the DBInterface
type DBWrapper struct {
	db *sqlx.DB
}

func (w *DBWrapper) ExecContext(ctx context.Context, query string, args ...interface{}) (sql.Result, error) {
	return w.db.ExecContext(ctx, query, args...)
}

var (
	cfg               *config.Config
	selfHealingEvents atomic.Uint64
	forceFrom         string
	Version           = "v2.2.0-intelligence-engine" // ğŸš€ å·¥ä¸šçº§ç‰ˆæœ¬å·
)

func getStartBlockFromCheckpoint(ctx context.Context, db *sqlx.DB, rpcPool engine.RPCClient, chainID int64, forceFrom string, resetDB bool) (*big.Int, error) {
	// 1. è·å–é“¾ä¸Šå®æ—¶é«˜åº¦
	latestChainBlock, rpcErr := rpcPool.GetLatestBlockNumber(ctx)

	if resetDB {
		slog.Info("ğŸš¨ DATABASE_RESET_REQUESTED", "action", "wiping_tables")
		_, err := db.ExecContext(ctx, "TRUNCATE TABLE blocks, transfers CASCADE; DELETE FROM sync_checkpoints;")
		if err != nil {
			slog.Error("reset_db_fail", "err", err)
		}
		return big.NewInt(10262444), nil
	}

	if forceFrom != "" {
		if forceFrom == "latest" {
			if rpcErr != nil {
				return big.NewInt(0), nil
			}
			return new(big.Int).Add(latestChainBlock, big.NewInt(1)), nil
		}
		if blockNum, ok := new(big.Int).SetString(forceFrom, 10); ok {
			return blockNum, nil
		}
	}

	if cfg.StartBlockStr == "latest" {
		if rpcErr != nil {
			return big.NewInt(0), nil
		}
		reorgSafetyOffset := int64(6)
		startBlock := new(big.Int).Sub(latestChainBlock, big.NewInt(reorgSafetyOffset))
		if startBlock.Cmp(big.NewInt(0)) < 0 {
			startBlock = big.NewInt(0)
		}
		return startBlock, nil
	}

	if cfg.StartBlock > 0 {
		return new(big.Int).SetInt64(cfg.StartBlock), nil
	}

	var lastSyncedBlock string
	err := db.GetContext(ctx, &lastSyncedBlock, "SELECT last_synced_block FROM sync_checkpoints WHERE chain_id = $1", chainID)
	if err != nil || lastSyncedBlock == "" {
		return big.NewInt(10262444), nil
	}

	blockNum, _ := new(big.Int).SetString(lastSyncedBlock, 10)
	if cfg.IsTestnet && chainID == 11155111 {
		minStartBlock := big.NewInt(10262444)
		if blockNum.Cmp(minStartBlock) < 0 {
			return minStartBlock, nil
		}
	}

	return new(big.Int).Add(blockNum, big.NewInt(1)), nil
}

// runSequencerWithSelfHealing å¯åŠ¨ Sequencer å¹¶åœ¨å´©æºƒåè‡ªåŠ¨é‡å¯
func runSequencerWithSelfHealing(ctx context.Context, sequencer *engine.Sequencer, wg *sync.WaitGroup) {
	defer wg.Done()
	for {
		select {
		case <-ctx.Done():
			slog.Info("ğŸ›‘ [SELF-HEAL] Sequencer supervisor stopped")
			return
		default:
			slog.Info("ğŸ”„ [SELF-HEAL] Starting Sequencer...")
			recovery.WithRecoveryNamed("sequencer_run", func() {
				sequencer.Run(ctx)
			})

			// å¦‚æœ Sequencer å´©æºƒé€€å‡ºï¼Œç­‰å¾… 3 ç§’åé‡å¯
			slog.Warn("âš ï¸ [SELF-HEAL] Sequencer crashed, restarting in 3s...")
			select {
			case <-ctx.Done():
				slog.Info("ğŸ›‘ [SELF-HEAL] Sequencer supervisor cancelled during restart delay")
				return
			case <-time.After(3 * time.Second):
				slog.Info("â™»ï¸ [SELF-HEAL] Sequencer restarting...")
			}
		}
	}
}

func main() {
	if err := run(); err != nil {
		os.Exit(1)
	}
}

func run() error {
	resetDB := flag.Bool("reset", false, "Reset database")
	startFrom := flag.String("start-from", "", "Force start from: 'latest' or specific block number")
	mode := flag.String("mode", "index", "Operation mode: 'index' or 'replay'")
	replayFile := flag.String("file", "", "Trajectory file for replay (.jsonl or .lz4)")
	replaySpeed := flag.Float64("speed", 1.0, "Replay speed factor (e.g. 2.0 for 2x speed, 0 for max speed)")
	flag.Parse()
	cfg = config.Load()
	engine.InitLogger(cfg.LogLevel)
	forceFrom = *startFrom

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ä¼˜åŒ–ï¼šä½¿ç”¨å¸¦èŠ‚æµçš„ WebSocket Hub
	// é¿å…é«˜é¢‘ Anvil ç¯å¢ƒä¸‹çš„ WS è¿æ¥éœ‡è¡
	var wsHub *web.Hub
	if cfg.ChainID == 31337 {
		// Anvil ç¯å¢ƒï¼š500ms èŠ‚æµé—´éš”ï¼Œèšåˆé«˜é¢‘äº‹ä»¶
		throttledHub := web.NewThrottledHub(500 * time.Millisecond)
		go throttledHub.RunWithThrottling(ctx)
		wsHub = throttledHub.Hub // æå–åŸºç¡€ Hub ä¾›å…¶ä»–ç»„ä»¶ä½¿ç”¨
		slog.Info("ğŸ”¥ Throttled WebSocket Hub activated for Anvil", "throttle", "500ms")
	} else {
		// ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨æ ‡å‡† Hub
		wsHub = web.NewHub()
		go wsHub.Run(ctx)
		slog.Info("ğŸ“¡ Standard WebSocket Hub activated for production")
	}

	// ğŸ¬ å¤„ç†å›æ”¾æ¨¡å¼
	if *mode == "replay" {
		if *replayFile == "" {
			slog.Error("âŒ Replay mode requires -file parameter")
			return fmt.Errorf("replay mode requires -file parameter")
		}
		db, err := connectDB(ctx, cfg.ChainID == 31337)
		if err != nil {
			return err
		}
		processor := engine.NewProcessor(db, nil, 100, cfg.ChainID, false, "replay")

		// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šå›æ”¾æ¨¡å¼ä¹Ÿå¯ç”¨å¼‚æ­¥è½ç›˜
		orchestrator := engine.GetOrchestrator()
		asyncWriter := engine.NewAsyncWriter(db, orchestrator, cfg.EphemeralMode)
		orchestrator.SetAsyncWriter(asyncWriter)
		asyncWriter.Start()

		slog.Info("ğŸ System starting in REPLAY mode.")
		if err := RunReplayMode(ctx, *replayFile, *replaySpeed, processor); err != nil {
			slog.Error("Replay failed", "err", err)
			return err
		}
		return nil
	}

	apiServer := NewServer(nil, wsHub, cfg.Port, cfg.AppTitle)
	recovery.WithRecovery(func() {
		slog.Info("ğŸš€ Indexer API Server starting (Early Bird Mode)", "port", cfg.Port)
		if err := apiServer.Start(); err != nil && err != http.ErrServerClosed {
			slog.Error("api_start_fail", "err", err)
		}
	}, "api_server")

	recovery.WithRecoveryNamed("async_init", func() {
		initEngine(ctx, apiServer, wsHub, *resetDB)
	})

	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
	slog.Info("ğŸ System Operational.")
	<-sigCh
	return nil
}

func initEngine(ctx context.Context, apiServer *Server, wsHub *web.Hub, resetDB bool) {
	slog.Info("â³ Async engine initialization started...")

	// ğŸš¨ Register Engine Health Watchdog: Broadcast panic to UI
	recovery.OnPanic = func(name string, err interface{}, _ string) {
		wsHub.Broadcast(web.WSEvent{
			Type: "engine_panic",
			Data: map[string]interface{}{
				"worker": name,
				"error":  fmt.Sprintf("%v", err),
				"ts":     time.Now().Unix(),
			},
		})
	}

	db, err := connectDB(ctx, cfg.ChainID == 31337)
	if err != nil {
		return
	}

	// ğŸ›¡ï¸ Ensure Schema is initialized (resolves token_metadata missing errors)
	if err := database.InitSchema(ctx, db); err != nil {
		slog.Error("âŒ Database schema initialization failed", "err", err)
		return
	}

	rpcPool, err := setupRPC()
	if err != nil {
		return
	}

	if err := verifyNetworkWithRetry(); err != nil {
		return
	}

	// ğŸš€ Dynamic Speed Control: ç¯å¢ƒæ„ŸçŸ¥æ€§èƒ½é…ç½®
	// è·å–æ€§èƒ½é…ç½®æ–‡ä»¶ï¼ˆè‡ªåŠ¨æ£€æµ‹ Anvil/ç”Ÿäº§ç¯å¢ƒï¼‰
	perfProfile := engine.GetPerformanceProfile(cfg.RPCURLs, cfg.ChainID)
	perfProfile.ApplyToConfig(cfg)

	// åº”ç”¨æ€§èƒ½é…ç½®
	concurrency := cfg.FetchConcurrency
	tpsLimit := cfg.RPCRateLimit

	if perfProfile.EnableAggressiveBatch {
		// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤æé™æ€§èƒ½é…ç½®
		concurrency = perfProfile.FetchConcurrency
		tpsLimit = int(perfProfile.TPSLimit)
		slog.Info("ğŸ”¥ YOKOHAMA LAB PROFILE ACTIVATED",
			"concurrency", concurrency,
			"tps_limit", tpsLimit,
			"batch_size", perfProfile.BatchSize,
			"channel_buffer", perfProfile.ChannelBufferSize,
		)
	} else if cfg.IsTestnet {
		// ğŸ›¡ï¸ Sepolia ç”Ÿäº§ç¯å¢ƒï¼šæåº¦ä¿å®ˆ
		concurrency = 1
		tpsLimit = 1
		slog.Info("ğŸ›¡ï¸ Quota protection ACTIVE: Enforcing 1.0 TPS strict serial sync")
	}

	sm := NewServiceManager(db, rpcPool, cfg.ChainID, cfg.RetryQueueSize, tpsLimit, tpsLimit*2, concurrency, cfg.EnableSimulator, cfg.NetworkMode, cfg.EnableRecording, cfg.RecordingPath)
	configureTokenFiltering(sm)
	sm.fetcher.SetThroughputLimit(float64(tpsLimit))

	// ğŸš€ å¯åŠ¨æœŸåŸºç¡€è®¾æ–½å¯¹é½ (è‡ªæ„ˆ)
	if err := sm.Processor.AlignInfrastructure(ctx, rpcPool); err != nil {
		slog.Error("âŒ [FATAL] Infrastructure alignment failed", "err", err)
		// ä¸¥é‡é”™è¯¯ï¼Œå»ºè®®é€€å‡ºæˆ–é™çº§ï¼Œè¿™é‡Œæš‚æ—¶è®°å½•é”™è¯¯
	}

	// ğŸš€ Industrial Guard: Align DB with Chain Absolute Truth
	guard := engine.NewConsistencyGuard(sm.Processor.GetRepoAdapter(), rpcPool)
	guard.SetDemoMode(cfg.DemoMode)

	// ğŸš€ Real-time reporting of alignment progress
	guard.OnStatus = func(status string, detail string, progress int) {
		wsHub.Broadcast(web.WSEvent{
			Type: "linearity_status",
			Data: map[string]interface{}{"status": status, "detail": detail, "progress": progress},
		})
	}

	if err := guard.PerformLinearityCheck(ctx); err != nil {
		slog.Error("linearity_check_failed", "err", err)
	}

	// ğŸ“ Configure HeightOracle with drift policy from config.
	engine.GetHeightOracle().StrictHeightCheck = true
	engine.GetHeightOracle().DriftTolerance = 5
	if cfg != nil {
		engine.GetHeightOracle().StrictHeightCheck = cfg.StrictHeightCheck
		engine.GetHeightOracle().DriftTolerance = cfg.DriftTolerance
	}

	// âœ¨ On-Demand Lifecycle: Stay active for 5 mins after any heartbeat (Web access)
	lazyManager := engine.NewLazyManager(sm.fetcher, rpcPool, 5*time.Minute, guard)

	// ğŸ”¥ è®¾ç½® ServiceManager çš„ lazyManager å¼•ç”¨ï¼ˆç”¨äºåŒºå—é“¾æ´»åŠ¨é€šçŸ¥ï¼‰
	sm.lazyManager = lazyManager

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ç¯å¢ƒå¼ºåˆ¶æ—è·¯ï¼šå½»åº•ç¦ç”¨ Eco-Mode å’Œé…é¢é™åˆ¶
	if cfg.ChainID == 31337 || engine.IsLocalAnvil(cfg.RPCURLs[0]) {
		lazyManager.SetAlwaysActive(true)
		slog.Info("ğŸ”¥ YOKOHAMA LAB BYPASS: Eco-Mode and Quota Enforcement disabled indefinitely",
			"chain_id", cfg.ChainID,
			"rpc", cfg.RPCURLs[0])

		// ğŸ”¥ è®¾ç½®æ— é™é…é¢
		sm.fetcher.SetThroughputLimit(100000.0)
		slog.Info("ğŸ”¥ YOKOHAMA LAB BYPASS: Quota set to unlimited (100k TPS)")
	}

	// ğŸ”¥ æ›´æ–° Prometheus æŒ‡æ ‡
	labModeEnabled := cfg.ChainID == 31337 || cfg.ForceAlwaysActive
	engine.GetMetrics().SetLabMode(labModeEnabled)

	lazyManager.StartMonitor(ctx)

	// ğŸ¼ SSOT: è®¢é˜… Orchestrator çŠ¶æ€å¿«ç…§ï¼Œé€šè¿‡ WS å¹¿æ’­
	orchestrator := engine.GetOrchestrator()
	snapshotCh := orchestrator.Subscribe()
	go func() {
		for snapshot := range snapshotCh {
			// å°† CoordinatorState è½¬æ¢ä¸º WS äº‹ä»¶
			wsEvent := web.WSEvent{
				Type: "status_update",
				Data: map[string]interface{}{
					"latest_height": snapshot.LatestHeight,
					"synced_cursor": snapshot.SyncedCursor,
					"transfers":     snapshot.Transfers,
					"is_eco_mode":   snapshot.IsEcoMode,
					"progress":      snapshot.Progress,
					"system_state":  snapshot.SystemState.String(),
					"updated_at":    snapshot.UpdatedAt.Format(time.RFC3339),
					"sync_lag":      snapshot.LatestHeight - snapshot.SyncedCursor,
				},
			}
			wsHub.Broadcast(wsEvent)
		}
	}()

	// ğŸš€ Real-time status broadcasting
	lazyManager.OnStatus = func(status map[string]interface{}) {
		wsHub.Broadcast(web.WSEvent{Type: "lazy_status", Data: status})
	}

	apiServer.SetDependencies(db, rpcPool, lazyManager, sm.Processor, cfg.ChainID)

	// ğŸš€ Single Source of Truth for Activity: All WS connections wake up the engine
	wsHub.OnActivity = func() {
		lazyManager.Trigger()
	}

	// ğŸ¨ On-Demand Coloring: When UI scrolls to a token, fetch its metadata
	wsHub.OnNeedMeta = func(addr string) {
		slog.Debug("ğŸ¨ [On-Demand] UI requested metadata", "address", addr)
		_ = sm.Processor.GetSymbol(common.HexToAddress(addr))
	}

	sm.Processor.EventHook = func(eventType string, data interface{}) {
		if apiServer.signer != nil {
			if signed, err := apiServer.signer.Sign(eventType, data); err == nil {
				wsHub.Broadcast(signed)
				return
			}
		}
		wsHub.Broadcast(web.WSEvent{Type: eventType, Data: data})
	}

	startBlock, err := sm.GetStartBlock(ctx, forceFrom, resetDB)
	if err != nil {
		slog.Error("failed_to_get_start_block", "err", err)
		return
	}

	setupParentAnchor(ctx, db, rpcPool, startBlock)
	initServices(ctx, sm, startBlock, lazyManager, rpcPool, wsHub)
}

func connectDB(ctx context.Context, isLocalAnvil bool) (*sqlx.DB, error) {
	dbCtx, cancel := context.WithTimeout(ctx, 15*time.Second)
	defer cancel()
	db, err := sqlx.ConnectContext(dbCtx, "pgx", cfg.DatabaseURL)
	if err != nil {
		slog.Error("âŒ Database connection failed", "err", err)
		return nil, err
	}

	if isLocalAnvil {
		// ğŸ”¥ Anvil å®éªŒå®¤é…ç½®ï¼šæ¿€è¿›è¿æ¥æ± ï¼ˆæ— é™ç«åŠ›ï¼‰
		db.SetMaxOpenConns(100)                 // æ— é™ç«åŠ›
		db.SetMaxIdleConns(20)                  // ä¿æŒçƒ­è¿æ¥
		db.SetConnMaxLifetime(30 * time.Minute) // æ›´é•¿ç”Ÿå‘½å‘¨æœŸ
		db.SetConnMaxIdleTime(5 * time.Minute)
		slog.Info("ğŸ”¥ Anvil database pool: 100 max connections (Lab Mode)")
	} else {
		// ğŸ›¡ï¸ ç”Ÿäº§ç¯å¢ƒï¼šä¿å®ˆé…ç½®ï¼ˆå®‰å…¨ç¬¬ä¸€ï¼‰
		db.SetMaxOpenConns(25)
		db.SetMaxIdleConns(10)
		db.SetConnMaxLifetime(5 * time.Minute)
		db.SetConnMaxIdleTime(1 * time.Minute)
		slog.Info("ğŸ›¡ï¸ Production database pool: 25 connections, safety first")
	}

	return db, nil
}

func setupRPC() (engine.RPCClient, error) {
	var rpcPool engine.RPCClient
	var err error
	if cfg.IsTestnet {
		rpcPool, err = engine.NewEnhancedRPCClientPoolWithTimeout(cfg.RPCURLs, cfg.IsTestnet, cfg.MaxSyncBatch, cfg.RPCTimeout)
	} else {
		rpcPool, err = engine.NewRPCClientPoolWithTimeout(cfg.RPCURLs, cfg.RPCTimeout)
	}
	if err == nil {
		rpcPool.SetRateLimit(float64(cfg.RPCRateLimit), cfg.RPCRateLimit*2)
	}
	return rpcPool, err
}

func verifyNetworkWithRetry() error {
	var verifyErr error
	for i := 0; i < 3; i++ {
		if ethClient, err := ethclient.Dial(cfg.RPCURLs[0]); err == nil {
			verifyErr = networkpkg.VerifyNetwork(ethClient, cfg.ChainID)
			ethClient.Close()
			if verifyErr == nil {
				return nil
			}
		} else {
			verifyErr = err
		}
		time.Sleep(2 * time.Second)
	}
	slog.Error("âŒ [FATAL] Network verification failed", "error", verifyErr)
	return verifyErr
}

func configureTokenFiltering(sm *ServiceManager) {
	var watched []string
	switch cfg.TokenFilterMode {
	case "all":
		watched = []string{}
	case "whitelist":
		watched = cfg.WatchedTokenAddresses
	default:
		watched = []string{}
	}
	sm.fetcher.SetWatchedAddresses(watched)
	sm.Processor.SetWatchedAddresses(watched)
}

func setupParentAnchor(ctx context.Context, db *sqlx.DB, rpcPool engine.RPCClient, startBlock *big.Int) {
	if startBlock.Cmp(big.NewInt(0)) <= 0 {
		return
	}
	parentNum := new(big.Int).Sub(startBlock, big.NewInt(1))
	anchorCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
	defer cancel()
	if parent, err := rpcPool.BlockByNumber(anchorCtx, parentNum); err == nil && parent != nil {
		if _, err := db.Exec("INSERT INTO blocks (number, hash, parent_hash, timestamp) VALUES ($1, $2, $3, $4) ON CONFLICT DO NOTHING",
			parentNum.String(), parent.Hash().Hex(), parent.ParentHash().Hex(), parent.Time()); err != nil {
			slog.Warn("failed_to_insert_parent_block_anchor", "err", err)
		}
	}
}

func initServices(ctx context.Context, sm *ServiceManager, startBlock *big.Int, lazyManager *engine.LazyManager, rpcPool engine.RPCClient, wsHub *web.Hub) {
	var wg sync.WaitGroup
	sm.fetcher.Start(ctx, &wg)
	fatalErrCh := make(chan error, 1024)
	sequencer := engine.NewSequencerWithFetcher(sm.Processor, sm.fetcher, startBlock, cfg.ChainID, sm.fetcher.Results, fatalErrCh, nil, engine.GetMetrics())

	go func() {
		for {
			select {
			case <-ctx.Done():
				return
			case err := <-fatalErrCh:
				if err != nil {
					slog.Error("ğŸš¨ [Sequencer] Fatal error reported", "err", err)
				}
			}
		}
	}()

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šè®¾ç½® Sequencer å¼•ç”¨åˆ° Fetcherï¼ˆç”¨äºèƒŒå‹æ£€æµ‹ï¼‰
	sm.fetcher.SetSequencer(sequencer)
	slog.Info("ğŸ”¥ Backpressure sensing enabled: Fetcher â†’ Sequencer linked")

	// ğŸ¼ SSOT: åˆå§‹åŒ– Orchestratorï¼ˆå•ä¸€æ§åˆ¶é¢ï¼‰
	orchestrator := engine.GetOrchestrator()
	orchestrator.Init(ctx, sm.fetcher, sequencer, sm.Processor, lazyManager, nil)
	slog.Info("ğŸ¼ Orchestrator initialized: SSOT control plane active")

	// ğŸš€ å¤„ç†å…¨å†…å­˜æ¨¡å¼ä¸å†·å¯åŠ¨å¯¹é½
	if cfg.EphemeralMode {
		orchestrator.ResetToZero()
		slog.Warn("ğŸ”¥ EPHEMERAL_MODE ACTIVE: Starting from Block 0. No data will be saved to disk.")
	} else {
		// åŠ è½½åˆå§‹é«˜åº¦ï¼Œé¿å… UI æ˜¾ç¤ºä¸º 0
		if err := orchestrator.LoadInitialState(sm.db, cfg.ChainID); err != nil {
			slog.Error("ğŸ¼ Orchestrator: Failed to load initial state", "err", err)
		}
	}

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šåˆå§‹åŒ–å¼‚æ­¥å†™å…¥å™¨ (Muscle)
	asyncWriter := engine.NewAsyncWriter(sm.Processor.GetDB(), orchestrator, cfg.EphemeralMode)
	orchestrator.SetAsyncWriter(asyncWriter)
	asyncWriter.Start()
	slog.Info("ğŸ”¥ AsyncWriter initialized and started: Yokohama Muscle Active")

	// ğŸ›¡ï¸ åˆå§‹åŒ–è‡ªæ„ˆå®¡è®¡å¼•æ“ (Immune System)
	healer := engine.NewSelfHealer(orchestrator)
	go healer.Start(ctx)
	slog.Info("ğŸ›¡ï¸ SelfHealer activated: Logic audit loop online")

	// ğŸ›¡ï¸ Deadlock Watchdog: enabled for all networks (Anvil, Sepolia, production).
	// Enable() is now unconditional; the old chainID==31337 gate has been removed.
	watchdog := engine.NewDeadlockWatchdog(
		cfg.ChainID,
		cfg.DemoMode,
		sequencer,
		sm.Processor.GetRepoAdapter(),
		rpcPool,
		lazyManager,
		engine.GetMetrics(),
	)

	// Lower gap threshold for fast-block networks (Sepolia ~12s blocks).
	if cfg.ChainID == 11155111 {
		watchdog.SetGapThreshold(500)
	}

	watchdog.SetFetcher(sm.fetcher)
	watchdog.Enable()

	watchdog.OnHealingTriggered = func(event engine.HealingEvent) {
		wsHub.Broadcast(web.WSEvent{
			Type: "system_healing",
			Data: event,
		})
	}

	watchdog.Start(ctx)

	slog.Info("ğŸ›¡ï¸ DeadlockWatchdog initialized and started",
		"chain_id", cfg.ChainID,
		"demo_mode", cfg.DemoMode)

	wg.Add(1)
	go runSequencerWithSelfHealing(ctx, sequencer, &wg)
	go recovery.WithRecoveryNamed("tail_follow", func() { sm.StartTailFollow(ctx, startBlock) })

	if cfg.EnableSimulator {
		wg.Add(1)
		go func() {
			defer wg.Done()
			// ğŸš€ CHAOS_MODE: Boosted to 10 TPS for high-fidelity simulation
			proSim := engine.NewProSimulator(cfg.RPCURLs[0], true, 10)
			proSim.Start()
		}()
	}
}

func continuousTailFollow(ctx context.Context, fetcher *engine.Fetcher, rpcPool engine.RPCClient, startBlock *big.Int) {
	slog.Info("ğŸ• [TailFollow] Starting continuous tail follow", "start_block", startBlock.String())
	lastScheduled := new(big.Int).Sub(startBlock, big.NewInt(1))

	// ğŸš€ å·¥ä¸šçº§ä¼˜åŒ–ï¼šæœ¬åœ° Anvil å®éªŒå®¤ä½¿ç”¨è¶…é«˜é¢‘è½®è¯¢ï¼ˆ100msï¼‰
	tickerInterval := 500 * time.Millisecond
	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤æ»‘åŠ¨æ—¶é—´çª—å£ï¼šAnvil ç¯å¢ƒä¸‹ï¼Œè°ƒåº¦æ›´æ¿€è¿›çš„èŒƒå›´
	schedulingWindow := big.NewInt(10) // é»˜è®¤è°ƒåº¦çª—å£ï¼š10 ä¸ªå—
	if cfg.ChainID == 31337 {
		tickerInterval = 100 * time.Millisecond
		schedulingWindow = big.NewInt(100) // Anvilï¼š100 ä¸ªå—çª—å£
		slog.Info("ğŸ”¥ Anvil TailFollow: 100ms hyper-frequency, 100-block sliding window")
	}
	ticker := time.NewTicker(tickerInterval)

	tickCount := 0
	for {
		select {
		case <-ctx.Done():
			slog.Info("ğŸ• [TailFollow] Context cancelled, stopping")
			return
		case <-ticker.C:
			tickCount++
			tip, err := rpcPool.GetLatestBlockNumber(ctx)
			if err != nil {
				if tickCount%10 == 1 {
					slog.Warn("ğŸ• [TailFollow] Failed to get tip", "err", err)
				}
			} else {
				// ğŸ”¥ SSOT: é€šè¿‡ Orchestrator æ›´æ–°é“¾å¤´ï¼ˆå•ä¸€æ§åˆ¶é¢ï¼‰
				orch := engine.GetOrchestrator()
				orch.UpdateChainHead(tip.Uint64())

				// ğŸš€ è·å–è€ƒè™‘å®‰å…¨ç¼“å†²åçš„ç›®æ ‡é«˜åº¦
				snap := orch.GetSnapshot()
				targetHeight := big.NewInt(int64(snap.TargetHeight))

				if targetHeight.Cmp(lastScheduled) > 0 {
					slog.Debug("ğŸ¼ [TailFollow] Chain head update dispatched", "tip", tip.String(), "target", targetHeight.String())

					// ğŸ”¥ æ»‘åŠ¨æ—¶é—´çª—å£æ‰¹å¤„ç†ï¼šè°ƒåº¦ lastScheduled+1 åˆ° targetHeight+schedulingWindow
					// è¿™ç¡®ä¿äº†å³ä¾¿æœ‰å®‰å…¨å«ï¼Œä¹Ÿèƒ½æ‰¹é‡è°ƒåº¦
					nextBlock := new(big.Int).Add(lastScheduled, big.NewInt(1))
					aggressiveTarget := new(big.Int).Add(targetHeight, schedulingWindow)

					slog.Debug("ğŸ• [TailFollow] Scheduling new range",
						"from", nextBlock.String(),
						"to", aggressiveTarget.String(),
						"target", targetHeight.String(),
						"window", schedulingWindow.Int64())
					if err := fetcher.Schedule(ctx, nextBlock, aggressiveTarget); err != nil {
						slog.Error("ğŸ• [TailFollow] Failed to schedule", "err", err)
						continue
					}
					lastScheduled.Set(targetHeight)
				}
			}
		}
	}
}
