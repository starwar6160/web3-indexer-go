package engine

import (
	"context"
	"log/slog"
	"math/big"
	"sort"
	"sync"
	"time"
)

// ReorgEvent è¡¨ç¤ºæ£€æµ‹åˆ°çš„ reorg äº‹ä»¶
type ReorgEvent struct {
	At *big.Int // reorg å‘ç”Ÿçš„é«˜åº¦
}

// BlockProcessor defines the interface for processing blocks
type BlockProcessor interface {
	ProcessBlockWithRetry(ctx context.Context, data BlockData, maxRetries int) error
	ProcessBatch(ctx context.Context, blocks []BlockData, chainID int64) error
	GetRPCClient() RPCClient
}

// Sequencer ç¡®ä¿åŒºå—æŒ‰é¡ºåºå¤„ç†ï¼Œè§£å†³å¹¶å‘æŠ“å–å¯¼è‡´çš„ä¹±åºé—®é¢˜
type Sequencer struct {
	expectedBlock *big.Int             // ä¸‹ä¸€ä¸ªæœŸæœ›å¤„ç†çš„åŒºå—å·
	buffer        map[string]BlockData // åŒºå—å· -> æ•°æ®çš„ç¼“å†²åŒº
	processor     BlockProcessor       // å®é™…å¤„ç†å™¨
	fetcher       *Fetcher             // ç”¨äºReorgæ—¶æš‚åœæŠ“å–
	mu            sync.RWMutex         // ä¿æŠ¤bufferå’ŒexpectedBlock
	resultCh      <-chan BlockData     // è¾“å…¥channel
	fatalErrCh    chan<- error         // è‡´å‘½é”™è¯¯é€šçŸ¥channel
	reorgCh       chan<- ReorgEvent    // reorg äº‹ä»¶é€šçŸ¥channel
	chainID       int64                // é“¾IDç”¨äºcheckpoint
	metrics       *Metrics             // Prometheus metrics

	lastProgressAt time.Time // ä¸Šæ¬¡å¤„ç†æˆåŠŸçš„æ—¶åˆ»
	gapFillCount   int       // è¿ç»­ gap-fill å°è¯•æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™é‡è¯•ï¼‰
}

func NewSequencer(processor BlockProcessor, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func NewSequencerWithFetcher(processor BlockProcessor, fetcher *Fetcher, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, reorgCh chan<- ReorgEvent, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		fetcher:        fetcher,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		reorgCh:        reorgCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func (s *Sequencer) Run(ctx context.Context) {
	Logger.Info("ğŸš€ Sequencer started", "expected_block", s.expectedBlock.String())

	stallTicker := time.NewTicker(30 * time.Second)
	defer stallTicker.Stop()

	processedCount := 0
	pulseTicker := time.NewTicker(10 * time.Second)
	defer pulseTicker.Stop()

	for {
		select {
		case <-ctx.Done():
			return

		case <-stallTicker.C:
			s.handleStall(ctx)

		case <-pulseTicker.C:
			slog.Info("ğŸš€ Sequencer: Pulse",
				"expected", s.expectedBlock.String(),
				"buffer", len(s.buffer),
				"processed_since_last", processedCount)
			processedCount = 0

		case data, ok := <-s.resultCh:
			if !ok {
				s.drainBuffer(ctx)
				return
			}

			batch := s.collectBatch(ctx, data)
			processedCount += len(batch)
			if err := s.handleBatch(ctx, batch); err != nil {
				// ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨éé˜»å¡ select å‘é€é”™è¯¯ï¼Œé˜²æ­¢ä¸‹æ¸¸æ¶ˆè´¹è€…ï¼ˆSupervisorï¼‰
				// å¤„ç†ä¸åŠæ—¶å¯¼è‡´ Sequencer ä¸»å¾ªç¯æ°¸ä¹…æ­»é”ã€‚
				select {
				case s.fatalErrCh <- err:
					// æˆåŠŸä¸ŠæŠ¥
				default:
					slog.Error("âš ï¸ Sequencer fatalErrCh full, dropping error report to avoid deadlock",
						"err", err.Error(),
						"expected", s.expectedBlock.String(),
						"buffer", len(s.buffer))
				}
				return
			}
		}
	}
}

func (s *Sequencer) handleStall(ctx context.Context) {
	s.mu.RLock()
	expectedStr := s.expectedBlock.String()
	expectedCopy := new(big.Int).Set(s.expectedBlock)
	_, hasExpected := s.buffer[expectedStr]
	bufferLen := len(s.buffer)
	idleTime := time.Since(s.lastProgressAt)

	var minBuffered *big.Int
	for numStr := range s.buffer {
		if n, ok := new(big.Int).SetString(numStr, 10); ok {
			if minBuffered == nil || n.Cmp(minBuffered) < 0 {
				minBuffered = n
			}
		}
	}
	s.mu.RUnlock()

	// ğŸ›¡ï¸ æ¼”ç¤ºæ¨¡å¼å¢å¼ºï¼š60 ç§’é˜ˆå€¼ï¼ˆä» 30 ç§’å»¶é•¿ï¼‰
	if idleTime > 60*time.Second {
		if bufferLen > 0 && !hasExpected {
			gapEnd := new(big.Int).Sub(minBuffered, big.NewInt(1))
			gapSize := new(big.Int).Sub(minBuffered, expectedCopy).Int64()
			Logger.Error("ğŸš¨ CRITICAL_GAP_DETECTED", slog.String("missing_from", expectedStr), slog.String("missing_to", gapEnd.String()), slog.Int64("gap_size", gapSize), slog.Int("buffered_blocks", bufferLen), slog.Int("gap_fill_attempt", s.gapFillCount+1))

			// ğŸ›¡ï¸ Gap Bypass Strategy: æœ€å¤šé‡è¯• 3 æ¬¡ï¼Œç„¶åå¼ºåˆ¶è·³è¿‡
			// è®¾è®¡ç†å¿µï¼šè®©æµæ°´çº¿ç»§ç»­æµï¼ŒæŠŠä¼¤ç–¤ç•™ç»™åå°å¼‚æ­¥è¡¥é½
			// å‚è€ƒ LMAX Disruptor çš„éé˜»å¡è®¾è®¡
			if s.fetcher != nil && s.gapFillCount < 3 {
				Logger.Info("ğŸ›¡ï¸ SELF_HEALING: Triggering batch gap-fill", slog.String("from", expectedStr), slog.String("to", gapEnd.String()), slog.Int("attempt", s.gapFillCount+1))
				go func(gapCtx context.Context) {
					if serr := s.fetcher.Schedule(gapCtx, expectedCopy, gapEnd); serr != nil {
						Logger.Warn("gap_refetch_schedule_failed", "err", serr)
					}
				}(ctx)
				s.gapFillCount++
			} else if bufferLen > 0 {
				// ğŸš€ å¼ºåˆ¶ç©ºæ´è·³è¿‡ï¼ˆForced Gap Bypassï¼‰
				// è®¾è®¡ç†å¿µï¼šåœ¨åšå½©/äº¤æ˜“ç³»ç»Ÿä¸­ï¼Œ"é˜»å¡ï¼ˆStallï¼‰"æ¯”"å»¶è¿Ÿ"æ›´å¯æ€•
				// è®©æµæ°´çº¿ç»§ç»­æµï¼ŒæŠŠç¼ºå¤±çš„å—æ ‡è®°ä¸º"å¾…è¡¥å¿"
				// æ³¨æ„ï¼šlastProgressAt å¿…é¡»åœ¨ä¿®æ”¹ expectedBlock ä¹‹å‰é‡ç½®
				skippedTo := new(big.Int).Sub(minBuffered, big.NewInt(1))
				Logger.Error("ğŸš§ GAP_BYPASS: Forced skip after max retries â€” pipeline unblocked",
					slog.String("skipped_from", expectedStr),
					slog.String("skipped_to", skippedTo.String()),
					slog.String("resume_at", minBuffered.String()),
					slog.Int("gap_fill_attempts", s.gapFillCount),
					slog.Int64("gap_size", gapSize),
					slog.String("strategy", "backfill_async"),
					slog.String("action_required", "replay skipped range to restore data completeness"))

				// ğŸ›¡ï¸ å…³é”®ï¼šlastProgressAt å¿…é¡»åœ¨è·å–é”ä¹‹å‰é‡ç½®
				// åŸå› ï¼š
				// 1. å¦‚æœåœ¨æŒæœ‰é”æ—¶é‡ç½®ï¼Œä¼šå¯¼è‡´ idleTime è®¡ç®—é”™è¯¯ï¼ˆå› ä¸ºæ—¶é—´æˆ³åœ¨é”å†…æ›´æ–°ï¼‰
				// 2. é‡ç½®å¿…é¡»åœ¨ expectedBlock æ›´æ–°ä¹‹å‰ï¼Œç¡®ä¿ watchdog æ£€æµ‹åˆ°"æœ‰è¿›å±•"
				// 3. è¿™æ ·å¯ä»¥é˜²æ­¢ gap bypass åç«‹å³å†æ¬¡è§¦å‘ stall æ£€æµ‹
				//
				// âš ï¸ è­¦å‘Šï¼šä¸è¦å°†è¿™è¡Œç§»åˆ° s.mu.Lock() ä¹‹åï¼Œå¦åˆ™ä¼šç ´åç©ºé—²æ£€æµ‹é€»è¾‘
				s.lastProgressAt = time.Now()

				s.mu.Lock()
				s.expectedBlock.Set(minBuffered)
				s.gapFillCount = 0
				s.mu.Unlock()
			}
		} else {
			// ğŸš¨ æ–°å¢ï¼šå¦‚æœ buffer ä¸ºç©ºä¸”è¶…è¿‡ 60 ç§’ï¼Œè¯´æ˜ Processor æˆ– MetadataEnricher é˜»å¡
			// å¼ºåˆ¶è·³è¿‡å½“å‰å—ï¼Œé¿å…æ¼”ç¤ºæœŸé—´å®Œå…¨å¡æ­»
			Logger.Error("ğŸš¨ CRITICAL_STALL: Processor/MetadataEnricher blocked, forcing skip",
				slog.String("stuck_at", expectedStr),
				slog.Duration("idle_time", idleTime),
				slog.Int("buffer_size", bufferLen))

			s.lastProgressAt = time.Now() // reset BEFORE lock to avoid immediate re-trigger

			s.mu.Lock()
			s.expectedBlock.Add(s.expectedBlock, big.NewInt(1))
			s.gapFillCount = 0
			s.mu.Unlock()
		}
	} else if idleTime > 30*time.Second {
		// 30 ç§’è­¦å‘Šçº§åˆ«ï¼ˆä» Error é™ä¸º Warnï¼‰
		Logger.Warn("âš ï¸ SEQUENCER_STALLED_DETECTED", slog.String("expected", expectedStr), slog.Int("buffer_size", bufferLen), slog.Duration("idle_time", idleTime))
	}
}

func (s *Sequencer) collectBatch(ctx context.Context, first BlockData) []BlockData {
	batch := []BlockData{first}
	maxBatchSize := 100
	timeout := time.After(10 * time.Millisecond)

collect_loop:
	for len(batch) < maxBatchSize {
		select {
		case nextData, ok := <-s.resultCh:
			if !ok {
				break collect_loop
			}
			batch = append(batch, nextData)
		case <-timeout:
			break collect_loop
		case <-ctx.Done():
			break collect_loop
		}
	}

	// ğŸš€ ä¼˜åŒ–æ’åºæ€§èƒ½ï¼šé¢„å¤„ç†æå–æ‰€æœ‰ block numberï¼Œé¿å…åœ¨æ¯”è¾ƒå‡½æ•°ä¸­é‡å¤è°ƒç”¨ getBlockNum
	type sortableBlock struct {
		idx int
		num *big.Int
	}
	nums := make([]sortableBlock, len(batch))
	for i, data := range batch {
		nums[i] = sortableBlock{idx: i, num: getBlockNum(data)}
	}

	sort.Slice(nums, func(i, j int) bool {
		if nums[i].num == nil {
			return true
		}
		if nums[j].num == nil {
			return false
		}
		return nums[i].num.Cmp(nums[j].num) < 0
	})

	// æ ¹æ®æ’åºåçš„ç´¢å¼•é‡å»ºåˆ‡ç‰‡
	sorted := make([]BlockData, len(batch))
	for i, nb := range nums {
		sorted[i] = batch[nb.idx]
	}
	return sorted
}

func getBlockNum(data BlockData) *big.Int {
	if data.Number != nil {
		return data.Number
	}
	if data.Block != nil {
		return data.Block.Number()
	}
	return nil
}

// GetIdleTime è¿”å› Sequencer çš„é—²ç½®æ—¶é—´ï¼ˆåªè¯»ï¼Œç”¨äºçœ‹é—¨ç‹—æ£€æµ‹ï¼‰
func (s *Sequencer) GetIdleTime() time.Duration {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return time.Since(s.lastProgressAt)
}

// GetExpectedBlock è¿”å›å½“å‰æœŸæœ›çš„åŒºå—å·ï¼ˆåªè¯»ï¼Œç”¨äºçœ‹é—¨ç‹—æ£€æµ‹ï¼‰
func (s *Sequencer) GetExpectedBlock() *big.Int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return new(big.Int).Set(s.expectedBlock)
}

// ResetExpectedBlock å¼ºåˆ¶é‡ç½®æœŸæœ›åŒºå—ï¼ˆçœ‹é—¨ç‹—ä¸“ç”¨ï¼‰
// åŒæ—¶é‡ç½®é—²ç½®è®¡æ—¶å™¨ï¼Œé¿å…ç«‹å³å†æ¬¡è§¦å‘çœ‹é—¨ç‹—
func (s *Sequencer) ResetExpectedBlock(block *big.Int) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.expectedBlock.Set(block)
	s.lastProgressAt = time.Now() // é‡ç½®é—²ç½®è®¡æ—¶å™¨
	Logger.Debug("ğŸ›¡ï¸ Sequencer: Expected block reset by watchdog",
		slog.String("new_expected", block.String()))
}

// ClearBuffer æ¸…ç©ºç¼“å†²åŒºï¼ˆçœ‹é—¨ç‹—ä¸“ç”¨ï¼‰
func (s *Sequencer) ClearBuffer() {
	s.mu.Lock()
	defer s.mu.Unlock()
	oldSize := len(s.buffer)
	s.buffer = make(map[string]BlockData)
	Logger.Debug("ğŸ›¡ï¸ Sequencer: Buffer cleared by watchdog",
		slog.Int("old_size", oldSize))
}
