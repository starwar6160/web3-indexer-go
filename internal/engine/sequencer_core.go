package engine

import (
	"context"
	"log/slog"
	"math/big"
	"sort"
	"sync"
	"time"
)

// ReorgEvent è¡¨ç¤ºæ£€æµ‹åˆ°çš„ reorg äº‹ä»¶
type ReorgEvent struct {
	At *big.Int // reorg å‘ç”Ÿçš„é«˜åº¦
}

// BlockProcessor defines the interface for processing blocks
type BlockProcessor interface {
	ProcessBlockWithRetry(ctx context.Context, data BlockData, maxRetries int) error
	ProcessBatch(ctx context.Context, blocks []BlockData, chainID int64) error
	GetRPCClient() RPCClient
}

// Sequencer ç¡®ä¿åŒºå—æŒ‰é¡ºåºå¤„ç†ï¼Œè§£å†³å¹¶å‘æŠ“å–å¯¼è‡´çš„ä¹±åºé—®é¢˜
type Sequencer struct {
	expectedBlock *big.Int             // ä¸‹ä¸€ä¸ªæœŸæœ›å¤„ç†çš„åŒºå—å·
	buffer        map[string]BlockData // åŒºå—å· -> æ•°æ®çš„ç¼“å†²åŒº
	processor     BlockProcessor       // å®é™…å¤„ç†å™¨
	fetcher       *Fetcher             // ç”¨äºReorgæ—¶æš‚åœæŠ“å–
	mu            sync.RWMutex         // ä¿æŠ¤bufferå’ŒexpectedBlock
	resultCh      <-chan BlockData     // è¾“å…¥channel
	fatalErrCh    chan<- error         // è‡´å‘½é”™è¯¯é€šçŸ¥channel
	reorgCh       chan<- ReorgEvent    // reorg äº‹ä»¶é€šçŸ¥channel
	chainID       int64                // é“¾IDç”¨äºcheckpoint
	metrics       *Metrics             // Prometheus metrics

	lastProgressAt time.Time // ä¸Šæ¬¡å¤„ç†æˆåŠŸçš„æ—¶åˆ»
	gapFillCount   int       // è¿ç»­ gap-fill å°è¯•æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™é‡è¯•ï¼‰
}

func NewSequencer(processor BlockProcessor, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func NewSequencerWithFetcher(processor BlockProcessor, fetcher *Fetcher, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, reorgCh chan<- ReorgEvent, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		fetcher:        fetcher,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		reorgCh:        reorgCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func (s *Sequencer) Run(ctx context.Context) {
	Logger.Info("ğŸš€ Sequencer started. Expected block: " + s.expectedBlock.String())

	stallTicker := time.NewTicker(30 * time.Second)
	defer stallTicker.Stop()

	for {
		select {
		case <-ctx.Done():
			return

		case <-stallTicker.C:
			s.handleStall(ctx)

		case data, ok := <-s.resultCh:
			if !ok {
				s.drainBuffer(ctx)
				return
			}

			batch := s.collectBatch(ctx, data)
			if err := s.handleBatch(ctx, batch); err != nil {
				select {
				case s.fatalErrCh <- err:
				case <-ctx.Done():
				}
				return
			}
		}
	}
}

func (s *Sequencer) handleStall(ctx context.Context) {
	s.mu.RLock()
	expectedStr := s.expectedBlock.String()
	expectedCopy := new(big.Int).Set(s.expectedBlock)
	_, hasExpected := s.buffer[expectedStr]
	bufferLen := len(s.buffer)
	idleTime := time.Since(s.lastProgressAt)

	var minBuffered *big.Int
	for numStr := range s.buffer {
		if n, ok := new(big.Int).SetString(numStr, 10); ok {
			if minBuffered == nil || n.Cmp(minBuffered) < 0 {
				minBuffered = n
			}
		}
	}
	s.mu.RUnlock()

	// ğŸ›¡ï¸ æ¼”ç¤ºæ¨¡å¼å¢å¼ºï¼š60 ç§’é˜ˆå€¼ï¼ˆä» 30 ç§’å»¶é•¿ï¼‰
	if idleTime > 60*time.Second {
		if bufferLen > 0 && !hasExpected {
			gapEnd := new(big.Int).Sub(minBuffered, big.NewInt(1))
			gapSize := new(big.Int).Sub(minBuffered, expectedCopy).Int64()
			Logger.Error("ğŸš¨ CRITICAL_GAP_DETECTED", slog.String("missing_from", expectedStr), slog.String("missing_to", gapEnd.String()), slog.Int64("gap_size", gapSize), slog.Int("buffered_blocks", bufferLen), slog.Int("gap_fill_attempt", s.gapFillCount+1))

			// ğŸ›¡ï¸ æ¼”ç¤ºæœŸé—´ï¼šå¦‚æœ gap-fill å¤±è´¥ 3 æ¬¡ï¼Œç«‹å³è·³è¿‡ï¼ˆä» 10 æ¬¡å‡å°‘ï¼‰
			if s.fetcher != nil && s.gapFillCount < 3 {
				Logger.Info("ğŸ›¡ï¸ SELF_HEALING: Triggering batch gap-fill", slog.String("from", expectedStr), slog.String("to", gapEnd.String()), slog.Int("attempt", s.gapFillCount+1))
				go func() {
					if serr := s.fetcher.Schedule(ctx, expectedCopy, gapEnd); serr != nil {
						Logger.Warn("gap_refetch_schedule_failed", "err", serr)
					}
				}()
				s.gapFillCount++
			} else if bufferLen > 0 {
				// è·³å—å…œåº•ï¼šgap-fill å¤šæ¬¡å¤±è´¥åè·³è¿‡ï¼Œä¿è¯ UI ä¸å¡æ­»ã€‚
				// è·³è¿‡çš„åŒºå—èŒƒå›´ä¼šè¢«è®°å½•ä¸ºç»“æ„åŒ–æ—¥å¿—ï¼Œä¾›è¿ç»´äººå‘˜é€šè¿‡ replay è¡¥å½•ã€‚
				// æ³¨æ„ï¼šlastProgressAt å¿…é¡»åœ¨ä¿®æ”¹ expectedBlock ä¹‹å‰é‡ç½®ï¼Œ
				// å¦åˆ™çœ‹é—¨ç‹—åœ¨ä¸‹ä¸€ä¸ª 30s tick æ—¶ä¼šç«‹å³å¯¹æ–°çš„ expectedBlock å†æ¬¡è§¦å‘ã€‚
				Logger.Error("ğŸš§ GAP_SKIP: Abandoning gap after max fill attempts â€” blocks will be missing",
					slog.String("skipped_from", expectedStr),
					slog.String("skipped_to", new(big.Int).Sub(minBuffered, big.NewInt(1)).String()),
					slog.String("resume_at", minBuffered.String()),
					slog.Int("gap_fill_attempts", s.gapFillCount),
					slog.String("action_required", "replay skipped range to restore data completeness"))

				s.lastProgressAt = time.Now() // reset BEFORE lock to avoid immediate re-trigger

				s.mu.Lock()
				s.expectedBlock.Set(minBuffered)
				s.gapFillCount = 0
				s.mu.Unlock()
			}
		} else {
			// ğŸš¨ æ–°å¢ï¼šå¦‚æœ buffer ä¸ºç©ºä¸”è¶…è¿‡ 60 ç§’ï¼Œè¯´æ˜ Processor æˆ– MetadataEnricher é˜»å¡
			// å¼ºåˆ¶è·³è¿‡å½“å‰å—ï¼Œé¿å…æ¼”ç¤ºæœŸé—´å®Œå…¨å¡æ­»
			Logger.Error("ğŸš¨ CRITICAL_STALL: Processor/MetadataEnricher blocked, forcing skip",
				slog.String("stuck_at", expectedStr),
				slog.Duration("idle_time", idleTime),
				slog.Int("buffer_size", bufferLen))

			s.lastProgressAt = time.Now() // reset BEFORE lock to avoid immediate re-trigger

			s.mu.Lock()
			s.expectedBlock.Add(s.expectedBlock, big.NewInt(1))
			s.gapFillCount = 0
			s.mu.Unlock()
		}
	} else if idleTime > 30*time.Second {
		// 30 ç§’è­¦å‘Šçº§åˆ«ï¼ˆä» Error é™ä¸º Warnï¼‰
		Logger.Warn("âš ï¸ SEQUENCER_STALLED_DETECTED", slog.String("expected", expectedStr), slog.Int("buffer_size", bufferLen), slog.Duration("idle_time", idleTime))
	}
}

func (s *Sequencer) collectBatch(ctx context.Context, first BlockData) []BlockData {
	batch := []BlockData{first}
	maxBatchSize := 100
	timeout := time.After(10 * time.Millisecond)

collect_loop:
	for len(batch) < maxBatchSize {
		select {
		case nextData, ok := <-s.resultCh:
			if !ok {
				break collect_loop
			}
			batch = append(batch, nextData)
		case <-timeout:
			break collect_loop
		case <-ctx.Done():
			break collect_loop
		}
	}

	sort.Slice(batch, func(i, j int) bool {
		n1 := getBlockNum(batch[i])
		n2 := getBlockNum(batch[j])
		if n1 == nil {
			return true
		}
		if n2 == nil {
			return false
		}
		return n1.Cmp(n2) < 0
	})
	return batch
}

func getBlockNum(data BlockData) *big.Int {
	if data.Number != nil {
		return data.Number
	}
	if data.Block != nil {
		return data.Block.Number()
	}
	return nil
}

// GetIdleTime è¿”å› Sequencer çš„é—²ç½®æ—¶é—´ï¼ˆåªè¯»ï¼Œç”¨äºçœ‹é—¨ç‹—æ£€æµ‹ï¼‰
func (s *Sequencer) GetIdleTime() time.Duration {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return time.Since(s.lastProgressAt)
}

// GetExpectedBlock è¿”å›å½“å‰æœŸæœ›çš„åŒºå—å·ï¼ˆåªè¯»ï¼Œç”¨äºçœ‹é—¨ç‹—æ£€æµ‹ï¼‰
func (s *Sequencer) GetExpectedBlock() *big.Int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return new(big.Int).Set(s.expectedBlock)
}

// ResetExpectedBlock å¼ºåˆ¶é‡ç½®æœŸæœ›åŒºå—ï¼ˆçœ‹é—¨ç‹—ä¸“ç”¨ï¼‰
// åŒæ—¶é‡ç½®é—²ç½®è®¡æ—¶å™¨ï¼Œé¿å…ç«‹å³å†æ¬¡è§¦å‘çœ‹é—¨ç‹—
func (s *Sequencer) ResetExpectedBlock(block *big.Int) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.expectedBlock.Set(block)
	s.lastProgressAt = time.Now() // é‡ç½®é—²ç½®è®¡æ—¶å™¨
	Logger.Debug("ğŸ›¡ï¸ Sequencer: Expected block reset by watchdog",
		slog.String("new_expected", block.String()))
}

// ClearBuffer æ¸…ç©ºç¼“å†²åŒºï¼ˆçœ‹é—¨ç‹—ä¸“ç”¨ï¼‰
func (s *Sequencer) ClearBuffer() {
	s.mu.Lock()
	defer s.mu.Unlock()
	oldSize := len(s.buffer)
	s.buffer = make(map[string]BlockData)
	Logger.Debug("ğŸ›¡ï¸ Sequencer: Buffer cleared by watchdog",
		slog.Int("old_size", oldSize))
}
