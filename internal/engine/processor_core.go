package engine

import (
	"context"
	"errors"
	"fmt"
	"log/slog"
	"math/big"
	"strings"
	"sync"
	"time"

	"web3-indexer-go/internal/models"

	"github.com/ethereum/go-ethereum/common"
	"github.com/jmoiron/sqlx"
)

// repositoryAdapter é€‚é… sqlx.DB åˆ° DBUpdater æ¥å£
type repositoryAdapter struct {
	db *sqlx.DB
}

func (r *repositoryAdapter) UpdateTokenSymbol(tokenAddress, symbol string) error {
	query := `UPDATE transfers SET symbol = $1 WHERE token_address = $2 AND (symbol IS NULL OR symbol = '')`
	_, err := r.db.Exec(query, symbol, tokenAddress)
	return err
}

func (r *repositoryAdapter) UpdateTokenDecimals(_ string, _ uint8) error {
	// é¢„ç•™æ–¹æ³•ï¼Œå½“å‰ schema æ²¡æœ‰ decimals å­—æ®µ
	return nil
}

func (r *repositoryAdapter) SaveTokenMetadata(meta models.TokenMetadata, address string) error {
	query := `
		INSERT INTO token_metadata (address, symbol, decimals, name, updated_at)
		VALUES ($1, $2, $3, $4, NOW())
		ON CONFLICT (address) DO UPDATE SET
			symbol = EXCLUDED.symbol,
			decimals = EXCLUDED.decimals,
			name = EXCLUDED.name,
			updated_at = NOW()
	`
	_, err := r.db.Exec(query, strings.ToLower(address), meta.Symbol, meta.Decimals, meta.Name)
	return err
}

func (r *repositoryAdapter) LoadAllMetadata() (map[string]models.TokenMetadata, error) {
	var rows []struct {
		Address  string `db:"address"`
		Symbol   string `db:"symbol"`
		Decimals uint8  `db:"decimals"`
		Name     string `db:"name"`
	}

	err := r.db.Select(&rows, "SELECT address, symbol, decimals, name FROM token_metadata")
	if err != nil {
		return nil, err
	}

	result := make(map[string]models.TokenMetadata)
	for _, row := range rows {
		result[strings.ToLower(row.Address)] = models.TokenMetadata{
			Symbol:   row.Symbol,
			Decimals: row.Decimals,
			Name:     row.Name,
		}
	}
	return result, nil
}

func (r *repositoryAdapter) GetMaxStoredBlock(ctx context.Context) (int64, error) {
	var dbMax int64
	err := r.db.GetContext(ctx, &dbMax, "SELECT COALESCE(MAX(number), 0) FROM blocks")
	return dbMax, err
}

func (r *repositoryAdapter) GetSyncCursor(ctx context.Context) (int64, error) {
	var cursor string
	err := r.db.GetContext(ctx, &cursor, "SELECT COALESCE(last_synced_block, '0') FROM sync_checkpoints LIMIT 1")
	if err != nil {
		return 0, err
	}
	num, _ := new(big.Int).SetString(cursor, 10)
	if num == nil {
		return 0, nil
	}
	return num.Int64(), nil
}

func (r *repositoryAdapter) PruneFutureData(ctx context.Context, chainHead int64) error {
	// Directly execute delete queries
	tx, err := r.db.BeginTxx(ctx, nil)
	if err != nil {
		return err
	}
	defer tx.Rollback() // nolint:errcheck // Rollback is standard practice, error is usually non-critical during cleanup

	headStr := fmt.Sprintf("%d", chainHead)

	if _, err := tx.ExecContext(ctx, "DELETE FROM transfers WHERE block_number > $1", headStr); err != nil {
		return err
	}
	if _, err := tx.ExecContext(ctx, "DELETE FROM blocks WHERE number > $1", headStr); err != nil {
		return err
	}
	if _, err := tx.ExecContext(ctx, "UPDATE sync_checkpoints SET last_synced_block = $1, updated_at = NOW()", headStr); err != nil {
		return err
	}
	return tx.Commit()
}

func (r *repositoryAdapter) UpdateSyncCursor(ctx context.Context, height int64) error {
	headStr := fmt.Sprintf("%d", height)
	if _, err := r.db.ExecContext(ctx, "UPDATE sync_checkpoints SET last_synced_block = $1, updated_at = NOW()", headStr); err != nil {
		return err
	}
	return nil
}

// TransferEventHash defined in signatures.go

// ErrReorgDetected is returned when a blockchain reorganization is detected
var ErrReorgDetected = errors.New("reorg detected: parent hash mismatch")

// ErrReorgNeedRefetch is returned when blocks need to be refetched due to reorg
var ErrReorgNeedRefetch = errors.New("reorg detected: need to refetch from common ancestor")

// ReorgError æºå¸¦è§¦å‘é«˜åº¦çš„ reorg é”™è¯¯ï¼ˆç”¨äºä¸Šå±‚å¤„ç†ï¼‰
type ReorgError struct {
	At *big.Int
}

func (e ReorgError) Error() string {
	return fmt.Sprintf("reorg detected at block %s", e.At.String())
}

type Processor struct {
	db               *sqlx.DB
	client           RPCClient // RPC client interface for reorg recovery
	metrics          *Metrics  // Prometheus metrics
	watchedAddresses map[common.Address]bool
	EventHook        func(eventType string, data interface{}) // å®æ—¶äº‹ä»¶å›è°ƒ

	// DLQ / Retry Queue
	retryQueue chan BlockData
	maxRetries int

	// Batch Checkpoint
	checkpointBatch           int
	blocksSinceLastCheckpoint int

	chainID         int64
	enableSimulator bool
	networkMode     string

	// ğŸ¨ Metadata Enricher (å¼‚æ­¥å…ƒæ•°æ®è§£æå™¨)
	enricher *MetadataEnricher

	// ğŸš€ HotBuffer (å†…å­˜çƒ­æ•°æ®æ± )
	hotBuffer *HotBuffer

	// ğŸš€ DataSink (å¤šè·¯åˆ†å‘æ”¯æŒ)
	sink DataSink

	// ğŸš€ Reorg æ£€æµ‹ç¼“å­˜ï¼šé¿å…æ¯å—éƒ½æŸ¥ DB
	lastBlockHashMu sync.Mutex
	lastBlockNum    int64
	lastBlockHash   string
}

func NewProcessor(db *sqlx.DB, client RPCClient, retryQueueSize int, chainID int64, enableSimulator bool, networkMode string) *Processor {
	p := &Processor{
		db:                        db,
		client:                    client,
		metrics:                   GetMetrics(),
		watchedAddresses:          make(map[common.Address]bool),
		retryQueue:                make(chan BlockData, retryQueueSize),
		maxRetries:                3,
		checkpointBatch:           100, // é»˜è®¤æ¯ 100 å—æŒä¹…åŒ–ä¸€æ¬¡
		blocksSinceLastCheckpoint: 0,
		chainID:                   chainID,
		enableSimulator:           enableSimulator,
		networkMode:               networkMode,
		hotBuffer:                 NewHotBuffer(50000), // é»˜è®¤ 5 ä¸‡æ¡çƒ­æ•°æ®
	}

	// ğŸ¨ åˆå§‹åŒ–å…ƒæ•°æ®ä¸°å¯Œå™¨ï¼ˆä»…ç”¨äºç”Ÿäº§ç½‘ç»œï¼ŒAnvil ä¸éœ€è¦ï¼‰
	if chainID != 31337 {
		// ä» RPC æ± ä¸­è·å–ä¸€ä¸ªå®¢æˆ·ç«¯ç”¨äºå…ƒæ•°æ®æŠ“å–
		var metadataClient LowLevelRPCClient
		if enhancedPool, ok := client.(*EnhancedRPCClientPool); ok {
			metadataClient = enhancedPool.GetClientForMetadata()
		}

		if metadataClient != nil {
			// ä½¿ç”¨ Repository åŒ…è£… db ä»¥æ»¡è¶³ DBUpdater æ¥å£
			repo := &repositoryAdapter{db: db}
			p.enricher = NewMetadataEnricher(metadataClient, repo, Logger)
			Logger.Info("ğŸ¨ [Processor] Metadata Enricher initialized", "chain_id", chainID)
		}
	}

	return p
}

// SetBatchCheckpoint è®¾ç½®æ£€æŸ¥ç‚¹æŒä¹…åŒ–æ‰¹æ¬¡å¤§å°
func (p *Processor) SetBatchCheckpoint(batchSize int) {
	p.checkpointBatch = batchSize
}

// StartRetryWorker å¯åŠ¨å¼‚æ­¥é‡è¯•å·¥äºº
func (p *Processor) StartRetryWorker(ctx context.Context, wg *sync.WaitGroup) {
	wg.Add(1)
	go func() {
		defer wg.Done()
		defer func() {
			if r := recover(); r != nil {
				Logger.Error("processor_retry_worker_panic", "err", r)
			}
		}()
		Logger.Info("processor_retry_worker_started")
		for {
			select {
			case <-ctx.Done():
				Logger.Info("processor_retry_worker_stopping")
				return
			case data := <-p.retryQueue:
				// ç®€å•çš„æŒ‡æ•°é€€é¿é‡è¯•é€»è¾‘å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•
				Logger.Warn("retrying_failed_block_from_queue",
					slog.String("block", data.Number.String()),
				)
				if err := p.ProcessBlockWithRetry(ctx, data, 1); err != nil {
					Logger.Error("block_failed_all_retries_sent_to_dead_letter",
						slog.String("block", data.Number.String()),
						slog.String("error", err.Error()),
					)
					// è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å°† data å†™å…¥æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¦‚æ•°æ®åº“ä¸­çš„ dead_letter_blocks è¡¨ï¼‰
				}
			}
		}
	}()
}

// SetWatchedAddresses sets the addresses to monitor
func (p *Processor) SetWatchedAddresses(addresses []string) {
	p.watchedAddresses = make(map[common.Address]bool)
	for _, addr := range addresses {
		p.watchedAddresses[common.HexToAddress(addr)] = true
		Logger.Info("processor_watching_address", slog.String("address", strings.ToLower(addr)))
	}
}

// GetDB returns the underlying sqlx.DB instance
func (p *Processor) GetDB() *sqlx.DB {
	return p.db
}

// GetRPCClient returns the RPC client used by the processor
func (p *Processor) GetRPCClient() RPCClient {
	return p.client
}

// GetSymbol returns the token symbol, triggering enrichment if missing
func (p *Processor) GetSymbol(addr common.Address) string {
	if p.enricher != nil {
		return p.enricher.GetSymbol(addr)
	}
	return addr.Hex()[:10] + "..."
}

// GetRepoAdapter returns the underlying repository adapter for the guard
func (p *Processor) GetRepoAdapter() DBUpdater {
	return &repositoryAdapter{db: p.db}
}

// GetHotBuffer returns the HotBuffer instance
func (p *Processor) GetHotBuffer() *HotBuffer {
	return p.hotBuffer
}

// SetSink sets the data sink for the processor
func (p *Processor) SetSink(sink DataSink) {
	p.sink = sink
}

// GetSink returns the current data sink
func (p *Processor) GetSink() DataSink {
	return p.sink
}

// ProcessBlockWithRetry å¸¦é‡è¯•çš„åŒºå—å¤„ç†
func (p *Processor) ProcessBlockWithRetry(ctx context.Context, data BlockData, maxRetries int) error {
	var err error

	for i := 0; i < maxRetries; i++ {
		err = p.ProcessBlock(ctx, data)
		if err == nil {
			return nil
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯è‡´å‘½é”™è¯¯ï¼ˆä¸éœ€è¦é‡è¯•ï¼‰
		if isFatalError(err) {
			return err
		}

		// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
		if ctx.Err() != nil {
			return ctx.Err()
		}

		// æŒ‡æ•°é€€é¿é‡è¯•ï¼š1s, 2s, 4s
		backoff := time.Duration(1<<i) * time.Second
		LogRPCRetry("ProcessBlock", i+1, err)
		select {
		case <-time.After(backoff):
			// ç»§ç»­é‡è¯•
		case <-ctx.Done():
			return ctx.Err()
		}
	}

	return fmt.Errorf("max retries exceeded for block %s: %w", func() string {
		if data.Block != nil {
			return data.Block.Number().String()
		}
		if data.Number != nil {
			return data.Number.String()
		}
		return "unknown"
	}(), err)
}

// isFatalError åˆ¤æ–­é”™è¯¯æ˜¯å¦ä¸éœ€è¦é‡è¯•
func isFatalError(err error) bool {
	if err == nil {
		return false
	}

	// Reorg æ£€æµ‹é”™è¯¯éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä¸æ˜¯ç®€å•é‡è¯•
	if err == ErrReorgDetected {
		return true
	}

	// ReorgError ä¹Ÿæ˜¯è‡´å‘½é”™è¯¯ï¼ˆéœ€è¦ä¸Šå±‚å¤„ç†ï¼‰
	if _, ok := err.(ReorgError); ok {
		return true
	}

	// ä¸Šä¸‹æ–‡å–æ¶ˆä¸éœ€è¦é‡è¯•
	if err == context.Canceled || err == context.DeadlineExceeded {
		return true
	}

	return false
}
