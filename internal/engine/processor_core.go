package engine

import (
	"context"
	"errors"
	"fmt"
	"log/slog"
	"math/big"
	"strings"
	"sync"
	"time"

	"github.com/ethereum/go-ethereum/common"
	"github.com/jmoiron/sqlx"
)

// TransferEventHash is the ERC20 Transfer event signature hash
// ğŸš€ å·¥ä¸šçº§ä¿®æ­£ï¼š0xddf252ad...0afda6
var TransferEventHash = common.HexToHash("0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f5514cfc0afda6")

// ErrReorgDetected is returned when a blockchain reorganization is detected
var ErrReorgDetected = errors.New("reorg detected: parent hash mismatch")

// ErrReorgNeedRefetch is returned when blocks need to be refetched due to reorg
var ErrReorgNeedRefetch = errors.New("reorg detected: need to refetch from common ancestor")

// ReorgError æºå¸¦è§¦å‘é«˜åº¦çš„ reorg é”™è¯¯ï¼ˆç”¨äºä¸Šå±‚å¤„ç†ï¼‰
type ReorgError struct {
	At *big.Int
}

func (e ReorgError) Error() string {
	return fmt.Sprintf("reorg detected at block %s", e.At.String())
}

type Processor struct {
	db               *sqlx.DB
	client           RPCClient // RPC client interface for reorg recovery
	metrics          *Metrics  // Prometheus metrics
	watchedAddresses map[common.Address]bool
	EventHook        func(eventType string, data interface{}) // å®æ—¶äº‹ä»¶å›è°ƒ

	// DLQ / Retry Queue
	retryQueue chan BlockData
	maxRetries int

	// Batch Checkpoint
	checkpointBatch           int
	blocksSinceLastCheckpoint int

	chainID int64
}

func NewProcessor(db *sqlx.DB, client RPCClient, retryQueueSize int, chainID int64) *Processor {
	p := &Processor{
		db:                        db,
		client:                    client,
		metrics:                   GetMetrics(),
		watchedAddresses:          make(map[common.Address]bool),
		retryQueue:                make(chan BlockData, retryQueueSize),
		maxRetries:                3,
		checkpointBatch:           100, // é»˜è®¤æ¯ 100 å—æŒä¹…åŒ–ä¸€æ¬¡
		blocksSinceLastCheckpoint: 0,
		chainID:                   chainID,
	}
	return p
}

// SetBatchCheckpoint è®¾ç½®æ£€æŸ¥ç‚¹æŒä¹…åŒ–æ‰¹æ¬¡å¤§å°
func (p *Processor) SetBatchCheckpoint(batchSize int) {
	p.checkpointBatch = batchSize
}

// StartRetryWorker å¯åŠ¨å¼‚æ­¥é‡è¯•å·¥äºº
func (p *Processor) StartRetryWorker(ctx context.Context, wg *sync.WaitGroup) {
	wg.Add(1)
	go func() {
		defer wg.Done()
		defer func() {
			if r := recover(); r != nil {
				Logger.Error("processor_retry_worker_panic", "err", r)
			}
		}()
		Logger.Info("processor_retry_worker_started")
		for {
			select {
			case <-ctx.Done():
				Logger.Info("processor_retry_worker_stopping")
				return
			case data := <-p.retryQueue:
				// ç®€å•çš„æŒ‡æ•°é€€é¿é‡è¯•é€»è¾‘å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•
				Logger.Warn("retrying_failed_block_from_queue",
					slog.String("block", data.Number.String()),
				)
				if err := p.ProcessBlockWithRetry(ctx, data, 1); err != nil {
					Logger.Error("block_failed_all_retries_sent_to_dead_letter",
						slog.String("block", data.Number.String()),
						slog.String("error", err.Error()),
					)
					// è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å°† data å†™å…¥æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¦‚æ•°æ®åº“ä¸­çš„ dead_letter_blocks è¡¨ï¼‰
				}
			}
		}
	}()
}

// SetWatchedAddresses sets the addresses to monitor
func (p *Processor) SetWatchedAddresses(addresses []string) {
	p.watchedAddresses = make(map[common.Address]bool)
	for _, addr := range addresses {
		p.watchedAddresses[common.HexToAddress(addr)] = true
		Logger.Info("processor_watching_address", slog.String("address", strings.ToLower(addr)))
	}
}

// ProcessBlockWithRetry å¸¦é‡è¯•çš„åŒºå—å¤„ç†
func (p *Processor) ProcessBlockWithRetry(ctx context.Context, data BlockData, maxRetries int) error {
	var err error

	for i := 0; i < maxRetries; i++ {
		err = p.ProcessBlock(ctx, data)
		if err == nil {
			return nil
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯è‡´å‘½é”™è¯¯ï¼ˆä¸éœ€è¦é‡è¯•ï¼‰
		if isFatalError(err) {
			return err
		}

		// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
		if ctx.Err() != nil {
			return ctx.Err()
		}

		// æŒ‡æ•°é€€é¿é‡è¯•ï¼š1s, 2s, 4s
		backoff := time.Duration(1<<i) * time.Second
		LogRPCRetry("ProcessBlock", i+1, err)
		select {
		case <-time.After(backoff):
			// ç»§ç»­é‡è¯•
		case <-ctx.Done():
			return ctx.Err()
		}
	}

	return fmt.Errorf("max retries exceeded for block %s: %w", func() string {
		if data.Block != nil {
			return data.Block.Number().String()
		}
		if data.Number != nil {
			return data.Number.String()
		}
		return "unknown"
	}(), err)
}

// isFatalError åˆ¤æ–­é”™è¯¯æ˜¯å¦ä¸éœ€è¦é‡è¯•
func isFatalError(err error) bool {
	if err == nil {
		return false
	}

	// Reorg æ£€æµ‹é”™è¯¯éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä¸æ˜¯ç®€å•é‡è¯•
	if err == ErrReorgDetected {
		return true
	}

	// ReorgError ä¹Ÿæ˜¯è‡´å‘½é”™è¯¯ï¼ˆéœ€è¦ä¸Šå±‚å¤„ç†ï¼‰
	if _, ok := err.(ReorgError); ok {
		return true
	}

	// ä¸Šä¸‹æ–‡å–æ¶ˆä¸éœ€è¦é‡è¯•
	if err == context.Canceled || err == context.DeadlineExceeded {
		return true
	}

	return false
}
