package engine

import (
	"context"
	"log/slog"
	"math/big"
	"sync"

	"web3-indexer-go/internal/limiter"

	"github.com/ethereum/go-ethereum/common"
	"github.com/ethereum/go-ethereum/core/types"
	"golang.org/x/time/rate"
)

type BlockData struct {
	Number   *big.Int
	RangeEnd *big.Int // Used for range processing (if applicable)
	Block    *types.Block
	Err      error
	Logs     []types.Log
}

type FetchJob struct {
	Start *big.Int
	End   *big.Int
}

type Fetcher struct {
	pool        RPCClient // RPCå®¢æˆ·ç«¯æ¥å£ï¼Œæ”¯æŒMockå’ŒçœŸå®å®ç°
	concurrency int
	jobs        chan FetchJob
	Results     chan BlockData
	limiter     *rate.Limiter // é€Ÿç‡é™åˆ¶å™¨
	throughput  *rate.Limiter // ğŸš€ Throughput limiter for visual/speed control
	bpsLimiter  *rate.Limiter // ğŸš€ ğŸ”¥ æ–°å¢ï¼šå—çº§åˆ«èŠ‚æ‹å™¨ (Pacemaker)
	stopCh      chan struct{} // ç”¨äºåœæ­¢è°ƒåº¦
	stopOnce    sync.Once     // ç¡®ä¿åªåœæ­¢ä¸€æ¬¡
	metrics     *Metrics      // Prometheus metrics

	// Pause/Resume æœºåˆ¶ï¼šç”¨ sync.Cond æ›¿ä»£ channel é¿å…ç«æ€
	pauseMu   sync.Mutex
	pauseCond *sync.Cond
	paused    bool

	// Watched addresses for contract monitoring
	watchedAddresses []common.Address

	headerOnlyMode bool          // ä½æˆæœ¬æ¨¡å¼ï¼šä»…è·å–åŒºå—å¤´ï¼Œä¸è·å–Logs
	recorder       *DataRecorder // ğŸ’¾ åŸå§‹æ•°æ®å½•åˆ¶å™¨

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šèƒŒå‹æ£€æµ‹
	sequencer *Sequencer // Sequencer å¼•ç”¨ï¼ˆç”¨äºæ£€æµ‹ buffer æ·±åº¦ï¼‰
}

// ğŸ”¥ QueueDepth è¿”å›é˜Ÿåˆ—æ·±åº¦ï¼ˆç”¨äºä¸Šæ¸¸èƒŒå‹æ£€æµ‹ï¼‰
func (f *Fetcher) QueueDepth() int {
	return len(f.jobs)
}

// ğŸ”¥ ResultsDepth è¿”å›ç»“æœé€šé“æ·±åº¦ï¼ˆç”¨äºä¸Šæ¸¸èƒŒå‹æ£€æµ‹ï¼‰
func (f *Fetcher) ResultsDepth() int {
	return len(f.Results)
}

// ğŸ”¥ SetSequencer è®¾ç½® Sequencer å¼•ç”¨ï¼ˆç”¨äºèƒŒå‹æ£€æµ‹ï¼‰
func (f *Fetcher) SetSequencer(seq *Sequencer) {
	f.sequencer = seq
}

// SetHeaderOnlyMode enables/disables low-cost mode
func (f *Fetcher) SetHeaderOnlyMode(enabled bool) {
	f.headerOnlyMode = enabled
	if enabled {
		Logger.Info("fetcher_switched_to_low_cost_header_only_mode")
	} else {
		Logger.Info("fetcher_switched_to_full_data_mode")
	}
}

func NewFetcher(pool RPCClient, concurrency int) *Fetcher {
	// å½»åº•å…³é—­é™é€Ÿ
	limiter := rate.NewLimiter(rate.Inf, 0)

	// ğŸ’¾ åˆå§‹åŒ–å½•åˆ¶å™¨
	recorder, err := NewDataRecorder("")
	if err != nil {
		slog.Warn("failed_to_initialize_recorder", "err", err)
	}

	f := &Fetcher{
		pool:        pool,
		concurrency: concurrency,
		// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šJobs channel ä¹Ÿæ‰©å®¹ (concurrency * 10)
		jobs: make(chan FetchJob, concurrency*10),
		// ğŸ”¥ 16G RAM è°ƒä¼˜ï¼šæå‡è‡³ 15,000ï¼Œç»™äºˆæ¶ˆè´¹ç«¯æ›´å¤šç¼“å†²ç©ºé—´
		Results:  make(chan BlockData, 15000),
		limiter:  limiter,
		recorder: recorder,
		stopCh:   make(chan struct{}),
		paused:   false,
		metrics:  GetMetrics(),
	}
	f.pauseCond = sync.NewCond(&f.pauseMu)
	return f
}

func NewFetcherWithLimiter(pool RPCClient, concurrency, rps, burst int) *Fetcher {
	// âœ¨ ä½¿ç”¨å·¥ä¸šçº§é™æµå™¨ï¼ˆè‡ªåŠ¨é™çº§ä¿æŠ¤ï¼‰
	rateLimiter := limiter.NewRateLimiter(rps)
	if burst > 0 {
		rateLimiter.Limiter().SetBurst(burst)
	}

	slog.Info("ğŸ›¡ï¸ Rate limiter initialized",
		"max_rps", rateLimiter.MaxRPS(),
		"concurrency", concurrency,
		"protection", "industrial_grade")

		// ğŸš€ Hard Throttle: Limit ingestion to 2.0 TPS to protect remaining quota

		throughput := rate.NewLimiter(rate.Limit(2.0), 1000)

	

		// ğŸš€ Pacemaker: æ¯ç§’æœ€å¤šå…è®¸å¤„ç† 200 ä¸ªå—ï¼Œç¡®ä¿ UI æ•°å­—åŒ€é€Ÿè·³åŠ¨

		bpsLimiter := rate.NewLimiter(rate.Limit(200.0), 50)

	

		// ğŸ’¾ åˆå§‹åŒ–å½•åˆ¶å™¨ (é»˜è®¤å­˜å‚¨è·¯å¾„)

		recorder, err := NewDataRecorder("")

		if err != nil {

			slog.Warn("failed_to_initialize_recorder", "err", err)

		}

	

		// ğŸ”¥ 16G RAM è°ƒä¼˜ï¼šæå‡è‡³ 15,000

		f := &Fetcher{

			pool:         pool,

			concurrency:  concurrency,

			jobs:         make(chan FetchJob, concurrency*10), // æ‰©å®¹ 10 å€

			Results:      make(chan BlockData, 15000),       // 16G RAM ç¯å¢ƒé€‚ä¸­é…ç½®

			limiter:      rateLimiter.Limiter(),

			throughput:   throughput,

			bpsLimiter:   bpsLimiter,

			recorder:     recorder,

			stopCh:       make(chan struct{}),

			paused:       false,

			metrics:      GetMetrics(),

		}
	f.pauseCond = sync.NewCond(&f.pauseMu)
	return f
}

// SetWatchedAddresses sets the contract addresses to monitor for Transfer events
func (f *Fetcher) SetWatchedAddresses(addresses []string) {
	f.watchedAddresses = make([]common.Address, 0, len(addresses))
	for _, addr := range addresses {
		if addr != "" {
			f.watchedAddresses = append(f.watchedAddresses, common.HexToAddress(addr))
		}
	}
}

// SetThroughputLimit updates the target processing speed
func (f *Fetcher) SetThroughputLimit(tps float64) {
	if tps <= 0 {
		f.throughput = rate.NewLimiter(rate.Inf, 0)
		return
	}
	// ğŸš€ å…è®¸ 1000 çš„ Burstï¼Œè¿™æ ·å³ä¾¿å¤§å—ä¹Ÿèƒ½è¿›å…¥é˜Ÿåˆ—ï¼Œä½†æ¶ˆè€—ä»¤ç‰Œä¼šäº§ç”Ÿåç»­å»¶è¿Ÿ
	f.throughput = rate.NewLimiter(rate.Limit(tps), 1000)
}

func (f *Fetcher) Start(ctx context.Context, wg *sync.WaitGroup) {
	Logger.Info("ğŸ“¢ [Fetcher] å¼•æ“åç¨‹å·²è¿›å…¥ Start å‡½æ•°ï¼",
		slog.Int("concurrency", f.concurrency),
	)
	for i := 0; i < f.concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			Logger.Info("ğŸŒ€ [Fetcher] å¾ªç¯æŠ“å–åç¨‹æ­£å¼å¯åŠ¨...",
				slog.Int("worker_id", workerID),
			)
			f.worker(ctx, wg)
		}(i)
	}
}

func (f *Fetcher) worker(ctx context.Context, wg *sync.WaitGroup) {
	defer wg.Done()

	for {
		select {
		case <-ctx.Done():
			return
		case <-f.stopCh:
			return
		case job, ok := <-f.jobs:
			if !ok {
				return
			}

			// ğŸš€ ğŸ”¥ æ–°å¢ï¼šå·¥ä½œè„‰æï¼Œå¸®åŠ©å®šä½ä¸ºä½• Jobs å µå¡
			slog.Debug("ğŸŒ€ [Fetcher] Worker picking up job", "start", job.Start.String(), "end", job.End.String())
			GetOrchestrator().DispatchLog("DEBUG", "ğŸŒ€ Fetcher: Worker processing job", "start", job.Start.String())

			// æ£€æŸ¥æ˜¯å¦æš‚åœï¼ˆReorg å¤„ç†æœŸé—´ï¼‰
			f.pauseMu.Lock()
			for f.paused {
				// ç­‰å¾…æ¢å¤ä¿¡å·ï¼ˆä½¿ç”¨ Cond.Wait é¿å…ç«æ€ï¼‰
				f.pauseCond.Wait()
			}
			f.pauseMu.Unlock()

			// æ£€æŸ¥æ˜¯å¦å·²åœæ­¢ï¼ˆåœ¨ unlock åå†æ£€æŸ¥ï¼‰
			select {
			case <-ctx.Done():
				return
			case <-f.stopCh:
				return
			default:
			}

			// ç­‰å¾…é€Ÿç‡é™åˆ¶ä»¤ç‰Œ
			if err := f.limiter.Wait(ctx); err != nil {
				select {
				case f.Results <- BlockData{Number: job.Start, RangeEnd: job.End, Err: err}:
				case <-ctx.Done():
					return
				case <-f.stopCh:
					return
				}
				continue
			}

			// è·å–èŒƒå›´åŒºå—æ•°æ®
			f.fetchRangeWithLogs(ctx, job.Start, job.End)
		}
	}
}
