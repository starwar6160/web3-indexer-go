package engine

import (
	"context"
	"fmt"
	"log/slog"
	"math/big"
	"sort"
	"sync"
	"time"

	"github.com/ethereum/go-ethereum"
	"github.com/ethereum/go-ethereum/common"
)

// ReorgEvent è¡¨ç¤ºæ£€æµ‹åˆ°çš„ reorg äº‹ä»¶
type ReorgEvent struct {
	At *big.Int // reorg å‘ç”Ÿçš„é«˜åº¦
}

// Sequencer ç¡®ä¿åŒºå—æŒ‰é¡ºåºå¤„ç†ï¼Œè§£å†³å¹¶å‘æŠ“å–å¯¼è‡´çš„ä¹±åºé—®é¢˜
type Sequencer struct {
	expectedBlock *big.Int             // ä¸‹ä¸€ä¸ªæœŸæœ›å¤„ç†çš„åŒºå—å·
	buffer        map[string]BlockData // åŒºå—å· -> æ•°æ®çš„ç¼“å†²åŒº
	processor     *Processor           // å®é™…å¤„ç†å™¨
	fetcher       *Fetcher             // ç”¨äºReorgæ—¶æš‚åœæŠ“å–
	mu            sync.RWMutex         // ä¿æŠ¤bufferå’ŒexpectedBlock
	resultCh      <-chan BlockData     // è¾“å…¥channel
	fatalErrCh    chan<- error         // è‡´å‘½é”™è¯¯é€šçŸ¥channel
	reorgCh       chan<- ReorgEvent    // reorg äº‹ä»¶é€šçŸ¥channel
	chainID       int64                // é“¾IDç”¨äºcheckpoint
	metrics       *Metrics             // Prometheus metrics

	lastProgressAt time.Time // ä¸Šæ¬¡å¤„ç†æˆåŠŸçš„æ—¶åˆ»
	gapFillCount   int       // è¿ç»­ gap-fill å°è¯•æ¬¡æ•°ï¼ˆé˜²æ­¢æ— é™é‡è¯•ï¼‰
}

func NewSequencer(processor *Processor, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func NewSequencerWithFetcher(processor *Processor, fetcher *Fetcher, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, reorgCh chan<- ReorgEvent, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock:  new(big.Int).Set(startBlock),
		buffer:         make(map[string]BlockData),
		processor:      processor,
		fetcher:        fetcher,
		resultCh:       resultCh,
		fatalErrCh:     fatalErrCh,
		reorgCh:        reorgCh,
		chainID:        chainID,
		metrics:        metrics,
		lastProgressAt: time.Now(),
	}
}

func (s *Sequencer) Run(ctx context.Context) {
	Logger.Info("ğŸš€ Sequencer started. Expected block: " + s.expectedBlock.String())

	stallTicker := time.NewTicker(30 * time.Second)
	defer stallTicker.Stop()

	for {
		select {
		case <-ctx.Done():
			return

		case <-stallTicker.C:
			// å·¡æ£€ï¼šå¦‚æœåœç•™åœ¨åŒä¸€ä¸ªå—è¶…è¿‡ 10sï¼Œè¯´æ˜å¯èƒ½é‡åˆ°äº†å“ˆå¸Œæ´æˆ–é€»è¾‘æ­»é”
			s.mu.RLock()
			expectedStr := s.expectedBlock.String()
			expectedCopy := new(big.Int).Set(s.expectedBlock)
			_, hasExpected := s.buffer[expectedStr]
			bufferLen := len(s.buffer)
			idleTime := time.Since(s.lastProgressAt)

			// æ‰«æ buffer æ‰¾åˆ°æœ€å°çš„å·²ç¼“å†²åŒºå—å·ï¼Œç¡®å®š gap èŒƒå›´
			var minBuffered *big.Int
			for numStr := range s.buffer {
				if n, ok := new(big.Int).SetString(numStr, 10); ok {
					if minBuffered == nil || n.Cmp(minBuffered) < 0 {
						minBuffered = n
					}
				}
			}
			s.mu.RUnlock()

			if idleTime > 30*time.Second {
				if bufferLen > 0 && !hasExpected {
					// ğŸš¨ å‘ç°å¹½çµç©ºæ´ï¼šç¼“å†²åŒºæœ‰åé¢å—ä½†æ²¡å½“å‰å—
					// è®¡ç®—éœ€è¦è¡¥é½çš„èŒƒå›´: [expected, minBuffered-1]
					gapEnd := new(big.Int).Sub(minBuffered, big.NewInt(1))
					gapSize := new(big.Int).Sub(minBuffered, expectedCopy).Int64()
					Logger.Error("ğŸš¨ CRITICAL_GAP_DETECTED",
						slog.String("missing_from", expectedStr),
						slog.String("missing_to", gapEnd.String()),
						slog.Int64("gap_size", gapSize),
						slog.Int("buffered_blocks", bufferLen),
						slog.Int("gap_fill_attempt", s.gapFillCount+1),
					)

					// è§¦å‘è‡ªæ„ˆï¼šå¼ºåˆ¶ Fetcher æ‰¹é‡é‡æ–°è°ƒåº¦æ‰€æœ‰ç¼ºå¤±çš„å—
					if s.fetcher != nil && s.gapFillCount < 10 {
						Logger.Info("ğŸ›¡ï¸ SELF_HEALING: Triggering batch gap-fill",
							slog.String("from", expectedStr),
							slog.String("to", gapEnd.String()),
						)
						go s.fetcher.Schedule(ctx, expectedCopy, gapEnd)
						s.gapFillCount++
					}
								} else {
									Logger.Warn("âš ï¸ SEQUENCER_STALLED_DETECTED", 
										slog.String("expected", expectedStr),
										slog.Int("buffer_size", bufferLen),
										slog.Duration("idle_time", idleTime),
									)
									if expectedStr == "1" || expectedStr == "0" {
										Logger.Info("ğŸ’¡ SRE_HINT: Indexer is healthy but upstream chain is idle. Please check if Anvil is mining or run 'python3 scripts/stress-test.py' to generate traffic.")
									}
								}
				
			}

		case data, ok := <-s.resultCh:
			if !ok {
				s.drainBuffer(ctx)
				return
			}

			// æ”¶é›†ä¸€ä¸ªæ‰¹æ¬¡çš„è¿ç»­åŒºå—è¿›è¡Œæ‰¹é‡å¤„ç†
			batch := []BlockData{data}
			maxBatchSize := 100

			// ç»™äºˆä¸€ä¸ªå°å°çš„ç­‰å¾…æ—¶é—´ï¼ˆ10msï¼‰ï¼Œè®©æ›´å¤šå—è¿›å…¥ channel
			// è¿™èƒ½æ˜¾è‘—æå‡æ‰¹é‡å¤„ç†çš„æœºä¼š
			timeout := time.After(10 * time.Millisecond)

		collect_loop:
			for len(batch) < maxBatchSize {
				select {
				case nextData, ok := <-s.resultCh:
					if !ok {
						break collect_loop
					}
					batch = append(batch, nextData)
				case <-timeout:
					break collect_loop
				default:
					if len(batch) > 0 {
						// å¦‚æœå·²ç»æœ‰æ•°æ®äº†ï¼Œä¸”ç›®å‰æ²¡æ–°æ•°æ®ï¼Œç¨å¾®ç­‰ä¸€ä¸‹æˆ–è€…ç›´æ¥å‡ºåœº
						// è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç›´æ¥å‡ºåœºï¼Œç”± timeout ä¿è¯æœ€ä½ç­‰å¾…
					}
				}
			}

			// å…³é”®ä¼˜åŒ–ï¼šå¯¹æ‰¹æ¬¡è¿›è¡Œæ’åºï¼Œä»¥æœ€å¤§åŒ–é¡ºåºå¤„ç†çš„å¯èƒ½æ€§
			// å› ä¸ºå¹¶å‘ fetcher ä¼šå¯¼è‡´ä¹±åºåˆ°è¾¾
			sort.Slice(batch, func(i, j int) bool {
				n1 := batch[i].Number
				if n1 == nil && batch[i].Block != nil {
					n1 = batch[i].Block.Number()
				}
				n2 := batch[j].Number
				if n2 == nil && batch[j].Block != nil {
					n2 = batch[j].Block.Number()
				}

				if n1 == nil {
					return true
				} // nil first (error handling)
				if n2 == nil {
					return false
				}

				return n1.Cmp(n2) < 0
			})

			if err := s.handleBatch(ctx, batch); err != nil {
				select {
				case s.fatalErrCh <- err:
				case <-ctx.Done():
				}
				return
			}
		}
	}
}

func (s *Sequencer) handleBatch(ctx context.Context, batch []BlockData) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// èƒŒå‹æ§åˆ¶ï¼šå¦‚æœç¼“å†²åŒºè¿‡å¤§ï¼Œæš‚åœ Fetcher
	if s.fetcher != nil && len(s.buffer) > 800 && !s.fetcher.IsPaused() {
		Logger.Warn("âš ï¸ sequencer_buffer_high_pausing_fetcher", slog.Int("buffer_size", len(s.buffer)))
		s.fetcher.Pause()
	}

	i := 0
	for i < len(batch) {
		data := batch[i]
		blockNum := data.Number
		if blockNum == nil && data.Block != nil {
			blockNum = data.Block.Number()
		}

		// å°è¯•æ‰¹é‡é¡ºåºå¤„ç†
		// åªæœ‰å½“å½“å‰å—æ²¡æœ‰é”™è¯¯æ—¶æ‰å°è¯•æ‰¹é‡ï¼Œå¦åˆ™èµ°å•æ¡å¤„ç†ä»¥è§¦å‘é‡è¯•é€»è¾‘
		if blockNum != nil && blockNum.Cmp(s.expectedBlock) == 0 && data.Err == nil {
			sequentialBatch := []BlockData{data}
			nextExpected := new(big.Int).Add(s.expectedBlock, big.NewInt(1))

			j := i + 1
			for j < len(batch) {
				nextData := batch[j]
				// å¦‚æœå‘ç°é”™è¯¯ï¼Œç«‹å³åœæ­¢æ‰¹æ¬¡æ”¶é›†ï¼Œç¡®ä¿é”™è¯¯å—é€šè¿‡ handleBlockLocked å¤„ç†
				if nextData.Err != nil {
					break
				}

				nNum := nextData.Number
				if nNum == nil && nextData.Block != nil {
					nNum = nextData.Block.Number()
				}

				if nNum != nil && nNum.Cmp(nextExpected) == 0 {
					sequentialBatch = append(sequentialBatch, nextData)
					nextExpected.Add(nextExpected, big.NewInt(1))
					j++
				} else {
					break
				}
			}

			if len(sequentialBatch) > 1 {
				Logger.Info("sequencer_processing_batch",
					slog.Int("size", len(sequentialBatch)),
					slog.String("from", sequentialBatch[0].Number.String()),
					slog.String("to", sequentialBatch[len(sequentialBatch)-1].Number.String()),
				)
				if err := s.processor.ProcessBatch(ctx, sequentialBatch, s.chainID); err != nil {
					return err
				}
				s.expectedBlock.Set(nextExpected)
				i = j
				s.processBufferContinuationsLocked(ctx)
				continue
			}
		}

		if err := s.handleBlockLocked(ctx, data); err != nil {
			return err
		}
		i++
	}
	return nil
}

func (s *Sequencer) handleBlock(ctx context.Context, data BlockData) error {
	s.mu.Lock()
	defer s.mu.Unlock()
	return s.handleBlockLocked(ctx, data)
}

func (s *Sequencer) handleBlockLocked(ctx context.Context, data BlockData) error {
	blockNum := data.Number
	if blockNum == nil && data.Block != nil {
		blockNum = data.Block.Number()
	}

	if data.Err != nil {
		Logger.Warn("sequencer_fetch_error_retrying", slog.String("block", blockNum.String()))
		if blockNum != nil {
			var err error
			data.Block, err = s.processor.client.BlockByNumber(ctx, blockNum)
			if err == nil {
				q := ethereum.FilterQuery{FromBlock: blockNum, ToBlock: blockNum, Topics: [][]common.Hash{{TransferEventHash}}}
				data.Logs, err = s.processor.client.FilterLogs(ctx, q)
				if err == nil {
					data.Err = nil
					Logger.Info("sequencer_retry_success", slog.String("block", blockNum.String()))
				}
			}
		}
		if data.Err != nil {
			return fmt.Errorf("fetch error for block %s: %w", blockNum.String(), data.Err)
		}
	}

	blockNum = data.Block.Number()
	if blockNum.Cmp(s.expectedBlock) == 0 {
		if err := s.processSequentialLocked(ctx, data); err != nil {
			return err
		}
		s.processBufferContinuationsLocked(ctx)
		return nil
	}

	if blockNum.Cmp(s.expectedBlock) < 0 {
		return nil
	}

	s.buffer[blockNum.String()] = data
	if len(s.buffer) > 1000 {
		return fmt.Errorf("sequencer buffer overflow: %d blocks", len(s.buffer))
	}
	return nil
}

func (s *Sequencer) processSequentialLocked(ctx context.Context, data BlockData) error {
	if err := s.processor.ProcessBlockWithRetry(ctx, data, 3); err != nil {
		if _, ok := err.(ReorgError); ok {
			return s.handleReorgLocked(ctx, data)
		}
		return err
	}
	s.expectedBlock.Add(s.expectedBlock, big.NewInt(1))
	s.lastProgressAt = time.Now() // ğŸ’¡ æˆåŠŸæ¨è¿›ï¼Œé‡ç½®è®¡æ—¶
	s.gapFillCount = 0            // é‡ç½® gap-fill è®¡æ•°å™¨
	return nil
}

func (s *Sequencer) processBufferContinuationsLocked(ctx context.Context) {
	for {
		nextNumStr := s.expectedBlock.String()
		data, exists := s.buffer[nextNumStr]
		if !exists {
			break
		}
		delete(s.buffer, nextNumStr)
		if err := s.processSequentialLocked(ctx, data); err != nil {
			s.buffer[nextNumStr] = data
			break
		}
	}

	// ç¼“å†²åŒºé™è‡³å®‰å…¨æ°´ä½ï¼Œæ¢å¤ Fetcher
	if s.fetcher != nil && len(s.buffer) < 200 && s.fetcher.IsPaused() {
		Logger.Info("âœ… sequencer_buffer_low_resuming_fetcher", slog.Int("buffer_size", len(s.buffer)))
		s.fetcher.Resume()
	}
}

func (s *Sequencer) handleReorgLocked(ctx context.Context, data BlockData) error {
	blockNum := data.Block.Number()
	if s.fetcher != nil {
		s.fetcher.Pause()
	}
	for numStr := range s.buffer {
		num, _ := new(big.Int).SetString(numStr, 10)
		if num.Cmp(blockNum) >= 0 {
			delete(s.buffer, numStr)
		}
	}
	s.expectedBlock.Set(blockNum)
	if s.reorgCh != nil {
		select {
		case s.reorgCh <- ReorgEvent{At: new(big.Int).Set(blockNum)}:
		case <-ctx.Done():
			return ctx.Err()
		}
	}
	return ErrReorgNeedRefetch
}

func (s *Sequencer) drainBuffer(ctx context.Context) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.processBufferContinuationsLocked(ctx)
}

func (s *Sequencer) GetExpectedBlock() *big.Int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return new(big.Int).Set(s.expectedBlock)
}

func (s *Sequencer) GetBufferSize() int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return len(s.buffer)
}
