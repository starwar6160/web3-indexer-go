package engine

import (
	"context"
	"fmt"
	"log"
	"math/big"
	"sync"
)

// ReorgEvent è¡¨ç¤ºæ£€æµ‹åˆ°çš„ reorg äº‹ä»¶
type ReorgEvent struct {
	At *big.Int // reorg å‘ç”Ÿçš„é«˜åº¦
}

// Sequencer ç¡®ä¿åŒºå—æŒ‰é¡ºåºå¤„ç†ï¼Œè§£å†³å¹¶å‘æŠ“å–å¯¼è‡´çš„ä¹±åºé—®é¢˜
type Sequencer struct {
	expectedBlock *big.Int             // ä¸‹ä¸€ä¸ªæœŸæœ›å¤„ç†çš„åŒºå—å·
	buffer        map[string]BlockData // åŒºå—å· -> æ•°æ®çš„ç¼“å†²åŒº (ä½¿ç”¨stringä½œä¸ºkeyé¿å…big.Intæ¯”è¾ƒé—®é¢˜)
	processor     *Processor           // å®é™…å¤„ç†å™¨
	fetcher       *Fetcher             // ç”¨äºReorgæ—¶æš‚åœæŠ“å–
	mu            sync.RWMutex         // ä¿æŠ¤bufferå’ŒexpectedBlock
	resultCh      <-chan BlockData     // è¾“å…¥channel
	fatalErrCh    chan<- error         // è‡´å‘½é”™è¯¯é€šçŸ¥channel
	reorgCh       chan<- ReorgEvent    // reorg äº‹ä»¶é€šçŸ¥channelï¼ˆå¯é€‰ï¼‰
	chainID       int64                // é“¾IDç”¨äºcheckpoint
	metrics       *Metrics             // Prometheus metrics
}

func NewSequencer(processor *Processor, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock: new(big.Int).Set(startBlock),
		buffer:        make(map[string]BlockData),
		processor:     processor,
		resultCh:      resultCh,
		fatalErrCh:    fatalErrCh,
		chainID:       chainID,
		metrics:       metrics,
	}
}

// NewSequencerWithFetcher åˆ›å»ºå¸¦ Fetcher æ§åˆ¶çš„ Sequencerï¼ˆæ¨èç”¨äº Reorg å¤„ç†ï¼‰
func NewSequencerWithFetcher(processor *Processor, fetcher *Fetcher, startBlock *big.Int, chainID int64, resultCh <-chan BlockData, fatalErrCh chan<- error, reorgCh chan<- ReorgEvent, metrics *Metrics) *Sequencer {
	return &Sequencer{
		expectedBlock: new(big.Int).Set(startBlock),
		buffer:        make(map[string]BlockData),
		processor:     processor,
		fetcher:       fetcher,
		resultCh:      resultCh,
		fatalErrCh:    fatalErrCh,
		reorgCh:       reorgCh,
		chainID:       chainID,
		metrics:       metrics,
	}
}

// Run å¯åŠ¨æ’åºå¤„ç†å™¨ï¼ŒæŒ‰é¡ºåºå¤„ç†åŒºå—
func (s *Sequencer) Run(ctx context.Context) {
	log.Printf("ğŸš€ Sequencer started. Expected block: %s", s.expectedBlock.String())

	// æ ‡è®°Sequencerå·²åˆå§‹åŒ–
	initialized := true
	_ = initialized

	for {
		select {
		case <-ctx.Done():
			log.Printf("Sequencer shutting down. Buffer size: %d", len(s.buffer))
			return

		case data, ok := <-s.resultCh:
			if !ok {
				// channelå…³é—­ï¼Œå°è¯•æ¸…ç©ºbuffer
				log.Printf("âš ï¸ Sequencer: resultCh closed, draining buffer...")
				s.drainBuffer(ctx)
				return
			}

			log.Printf("ğŸ“¦ Sequencer received block: %s", data.Block.Number().String())

			if err := s.handleBlock(ctx, data); err != nil {
				log.Printf("âŒ Sequencer error handling block: %v", err)
				// è‡´å‘½é”™è¯¯ï¼Œé€šçŸ¥å¤–å±‚å…³é—­
				select {
				case s.fatalErrCh <- err:
					log.Printf("ğŸ“¢ Sent fatal error to fatalErrCh")
				case <-ctx.Done():
				}
				return
			}
		}
	}
}

// handleBlock å¤„ç†å•ä¸ªåŒºå—æ•°æ®ï¼Œç»´æŠ¤é¡ºåºæ€§
func (s *Sequencer) handleBlock(ctx context.Context, data BlockData) error {
	if data.Err != nil {
		return fmt.Errorf("fetch error for block: %w", data.Err)
	}

	blockNum := data.Block.Number()
	blockNumStr := blockNum.String()

	s.mu.Lock()
	defer s.mu.Unlock()

	// å¦‚æœè¿™ä¸ªåŒºå—æ­£æ˜¯æˆ‘ä»¬æœŸæœ›çš„ä¸‹ä¸€ä¸ªï¼Œç«‹å³å¤„ç†
	if blockNum.Cmp(s.expectedBlock) == 0 {
		if err := s.processSequential(ctx, data); err != nil {
			return err
		}

		// æ£€æŸ¥bufferä¸­æ˜¯å¦æœ‰è¿ç»­çš„åç»­åŒºå—å¯ä»¥å¤„ç†
		s.processBufferContinuations(ctx)
		return nil
	}

	// å¦‚æœåŒºå—å·å°äºæœŸæœ›çš„ï¼Œè¯´æ˜å·²ç»å¤„ç†è¿‡äº†ï¼Œè·³è¿‡
	if blockNum.Cmp(s.expectedBlock) < 0 {
		log.Printf("Skipping duplicate/late block %s (expected %s)", blockNumStr, s.expectedBlock.String())
		return nil
	}

	// åŒºå—å·å¤§äºæœŸæœ›çš„ï¼Œå­˜å…¥bufferç­‰å¾…
	log.Printf("Buffering out-of-order block %s (expected %s). Buffer size: %d",
		blockNumStr, s.expectedBlock.String(), len(s.buffer)+1)
	s.buffer[blockNumStr] = data

	// Update metrics
	bufferSize := len(s.buffer)
	s.metrics.UpdateSequencerBufferSize(bufferSize)

	// åˆ†çº§å‘Šè­¦ï¼šbuffer è†¨èƒ€
	if bufferSize > 500 {
		LogBufferFull(bufferSize, s.expectedBlock.String())
		s.metrics.RecordSequencerBufferFull()
	}

	// å¦‚æœbufferè¿‡å¤§ï¼Œå¯èƒ½æ˜¯å‰é¢çš„åŒºå—ä¸¢å¤±äº†ï¼Œéœ€è¦è‡´å‘½å‘Šè­¦
	if bufferSize > 1000 {
		return fmt.Errorf("sequencer buffer overflow: %d blocks pending", bufferSize)
	}

	return nil
}

// processSequential æŒ‰é¡ºåºå¤„ç†åŒºå—å¹¶æ›´æ–°checkpoint
func (s *Sequencer) processSequential(ctx context.Context, data BlockData) error {
	blockNum := data.Block.Number()

	// æ‰§è¡Œå¤„ç†ï¼ˆå¸¦é‡è¯•ï¼‰
	if err := s.processor.ProcessBlockWithRetry(ctx, data, 3); err != nil {
		// åŒºåˆ†reorgé”™è¯¯å’Œè‡´å‘½é”™è¯¯
		if _, ok := err.(ReorgError); ok {
			// reorgéœ€è¦ç‰¹æ®Šå¤„ç†ï¼šæ¸…ç©ºbufferï¼Œé‡ç½®expected blockï¼Œå‘é€äº‹ä»¶
			return s.handleReorg(ctx, data)
		}
		return fmt.Errorf("failed to process block %s: %w", blockNum.String(), err)
	}

	// æˆåŠŸå¤„ç†åæ¨è¿›æœŸæœ›å€¼
	s.expectedBlock.Add(s.expectedBlock, big.NewInt(1))
	return nil
}

// processBufferContinuations å¤„ç†bufferä¸­è¿ç»­çš„åŒºå—
func (s *Sequencer) processBufferContinuations(ctx context.Context) {
	for {
		nextNumStr := s.expectedBlock.String()
		data, exists := s.buffer[nextNumStr]
		if !exists {
			break
		}

		delete(s.buffer, nextNumStr)

		if err := s.processSequential(ctx, data); err != nil {
			// è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ï¼Œè®©å¤–å±‚é€šè¿‡channelå¤„ç†
			log.Printf("Error processing buffered block %s: %v", nextNumStr, err)
			// æ”¾å›bufferç¨åé‡è¯•
			s.buffer[nextNumStr] = data
			break
		}

		log.Printf("Processed buffered block %s", nextNumStr)
		LogBlockProcessing(nextNumStr, data.Block.Hash().Hex(), 0)
	}
}

// handleReorg å¤„ç†é‡ç»„äº‹ä»¶
func (s *Sequencer) handleReorg(ctx context.Context, data BlockData) error {
	blockNum := data.Block.Number()

	// æš‚åœ Fetcher é˜²æ­¢ç»§ç»­å†™å…¥æ—§åˆ†å‰æ•°æ®
	if s.fetcher != nil {
		s.fetcher.Pause()
	}

	// æ¸…ç©ºæ‰€æœ‰å¤§äºç­‰äºå½“å‰åŒºå—çš„bufferæ•°æ®ï¼ˆè¿™äº›å¯èƒ½æ˜¯æ—§åˆ†å‰çš„æ•°æ®ï¼‰
	toDelete := []string{}
	for numStr := range s.buffer {
		num := new(big.Int)
		num.SetString(numStr, 10)
		if num.Cmp(blockNum) >= 0 {
			toDelete = append(toDelete, numStr)
		}
	}
	for _, numStr := range toDelete {
		delete(s.buffer, numStr)
	}

	// é‡ç½®expected blockåˆ°reorgç‚¹
	s.expectedBlock.Set(blockNum)

	// å‘é€ reorg äº‹ä»¶ç»™ mainï¼ˆå¦‚æœæœ‰ reorgChï¼‰
	if s.reorgCh != nil {
		select {
		case s.reorgCh <- ReorgEvent{At: new(big.Int).Set(blockNum)}:
		case <-ctx.Done():
			return ctx.Err()
		}
	}

	// è¿”å›ç‰¹æ®Šé”™è¯¯ï¼Œé€šçŸ¥å¤–å±‚éœ€è¦é‡æ–°è°ƒåº¦fetch
	return ErrReorgNeedRefetch
}

// drainBuffer å°è¯•åœ¨å…³é—­å‰æ¸…ç©ºbuffer
func (s *Sequencer) drainBuffer(ctx context.Context) {
	s.mu.Lock()
	defer s.mu.Unlock()

	for len(s.buffer) > 0 {
		nextNumStr := s.expectedBlock.String()
		data, exists := s.buffer[nextNumStr]
		if !exists {
			log.Printf("Cannot drain buffer: missing block %s, remaining: %d", nextNumStr, len(s.buffer))
			return
		}

		delete(s.buffer, nextNumStr)

		if err := s.processor.ProcessBlockWithRetry(ctx, data, 3); err != nil {
			log.Printf("Failed to drain block %s: %v", nextNumStr, err)
			return
		}

		s.expectedBlock.Add(s.expectedBlock, big.NewInt(1))
	}
}

// GetExpectedBlock è¿”å›å½“å‰æœŸæœ›çš„åŒºå—å·ï¼ˆç”¨äºå¤–éƒ¨ç›‘æ§ï¼‰
func (s *Sequencer) GetExpectedBlock() *big.Int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return new(big.Int).Set(s.expectedBlock)
}

// GetBufferSize è¿”å›å½“å‰ç¼“å†²åŒºå¤§å°ï¼ˆç”¨äºå¤–éƒ¨ç›‘æ§ï¼‰
func (s *Sequencer) GetBufferSize() int {
	s.mu.RLock()
	defer s.mu.RUnlock()
	return len(s.buffer)
}
