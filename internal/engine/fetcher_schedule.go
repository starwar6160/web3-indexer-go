package engine

import (
	"context"
	"fmt"
	"log/slog"
	"math/big"
)

func (f *Fetcher) Schedule(ctx context.Context, start, end *big.Int) error {
	Logger.Info("ğŸ“‹ [Fetcher] Schedule å¼€å§‹è°ƒåº¦ä»»åŠ¡",
		slog.String("start_block", start.String()),
		slog.String("end_block", end.String()),
	)

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šä¸Šæ¸¸èƒŒå‹æ£€æµ‹
	// æ£€æŸ¥ä¸‹æ¸¸æ°´ä½çº¿ï¼Œé¿å…æ— ç•Œè°ƒåº¦å¯¼è‡´èƒŒå‹
	jobsDepth := len(f.jobs)
	resultsDepth := len(f.Results)
	maxJobsCapacity := cap(f.jobs)
	maxResultsCapacity := cap(f.Results)

	// æ°´ä½çº¿é˜ˆå€¼
	jobsWatermark := maxJobsCapacity * 80 / 100       // 80%
	resultsWatermark := maxResultsCapacity * 80 / 100 // 80%

	if jobsDepth > jobsWatermark {
		Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Jobs queue too deep",
			slog.Int("jobs_depth", jobsDepth),
			slog.Int("jobs_watermark", jobsWatermark),
			slog.Int("jobs_capacity", maxJobsCapacity),
			slog.Int("results_depth", resultsDepth))
		return fmt.Errorf("fetcher jobs queue backpressure: depth=%d/%d", jobsDepth, maxJobsCapacity)
	}

	if resultsDepth > resultsWatermark {
		Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Results channel too deep",
			slog.Int("results_depth", resultsDepth),
			slog.Int("results_watermark", resultsWatermark),
			slog.Int("results_capacity", maxResultsCapacity),
			slog.Int("jobs_depth", jobsDepth))
		return fmt.Errorf("fetcher results channel backpressure: depth=%d/%d", resultsDepth, maxResultsCapacity)
	}

	// ğŸ”¥ æ£€æŸ¥ Sequencer buffer æ·±åº¦
	// æ¨ªæ»¨å®éªŒå®¤ï¼šæå‡é˜ˆå€¼è‡³ 2000 (128G RAM å¯æ‰¿å—)
	if f.sequencer != nil {
		seqBufferSize := f.sequencer.GetBufferSize()
		if seqBufferSize > 2000 {
			Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Sequencer buffer too deep",
				slog.Int("sequencer_buffer_size", seqBufferSize),
				slog.Int("jobs_depth", jobsDepth),
				slog.Int("results_depth", resultsDepth))
			return fmt.Errorf("sequencer buffer backpressure: size=%d", seqBufferSize)
		}
	}

	// å·¥ä¸šçº§å»ºè®®ï¼šRange æŸ¥è¯¢æ­¥é•¿
	// æ­£å¸¸åŒæ­¥ä½¿ç”¨ 50 ä¸ªå—ï¼ŒCatch-up æ—¶å¯ä»¥æ›´å¤§
	batchSize := big.NewInt(50)
	current := new(big.Int).Set(start)
	jobCount := 0

	for current.Cmp(end) <= 0 {
		batchEnd := new(big.Int).Add(current, batchSize)
		if batchEnd.Cmp(end) > 0 {
			batchEnd = new(big.Int).Set(end)
		}

		job := FetchJob{
			Start: new(big.Int).Set(current),
			End:   new(big.Int).Set(batchEnd),
		}

		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-f.stopCh:
			return fmt.Errorf("fetcher stopped")
		case f.jobs <- job:
			jobCount++
		}

		// ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹
		current = new(big.Int).Add(batchEnd, big.NewInt(1))
	}

	Logger.Info("ğŸ“‹ [Fetcher] Schedule å®Œæˆï¼Œæ‰€æœ‰ä»»åŠ¡å·²å‘é€",
		slog.Int("total_jobs", jobCount),
	)
	return nil
}
