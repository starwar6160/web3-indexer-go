package engine

import (
	"context"
	"errors"
	"fmt"
	"log/slog"
	"math/big"
)

// ErrBlockNotYetAvailable è¡¨ç¤ºè¯·æ±‚çš„åŒºå—é«˜åº¦è¶…è¿‡äº†å½“å‰é“¾é«˜åº¦
var ErrBlockNotYetAvailable = errors.New("block not yet available")

func (f *Fetcher) Schedule(ctx context.Context, start, end *big.Int) error {
	// ğŸš€ ğŸ”¥ è¾¹ç•Œå«å…µï¼šç»å¯¹ç¦æ­¢æŠ“å–è¿˜æœªäº§ç”Ÿçš„å— (Ghost Chase Defense)
	orch := GetOrchestrator()
	snap := orch.GetSnapshot()
	chainHeight := big.NewInt(int64(snap.LatestHeight))

	if start.Cmp(chainHeight) > 0 {
		// å¦‚æœæ˜¯ Anvil æ¨¡å¼ï¼Œä»…è®°å½• Debug è€Œé Errorï¼Œå‡å°‘æ—¥å¿—å™ªéŸ³
		slog.Debug("ğŸŒ€ [Fetcher] Boundary skip: start block is ahead of chain", "start", start.String(), "chain", chainHeight.String())
		return ErrBlockNotYetAvailable // è¿”å›ç‰¹å®šé”™è¯¯è®©è°ƒç”¨æ–¹èƒ½åŒºåˆ†"è·³è¿‡"å’Œ"æˆåŠŸ"
	}

	// å¦‚æœ end è¶…è¿‡äº† chainHeightï¼Œè‡ªåŠ¨æˆªæ–­åˆ° chainHeight
	if end.Cmp(chainHeight) > 0 {
		slog.Debug("ğŸŒ€ [Fetcher] Truncating schedule range to chain height", "original_end", end.String(), "new_end", chainHeight.String())
		end = chainHeight
	}

	if start.Cmp(end) > 0 {
		return nil
	}

	Logger.Info("ğŸ“‹ [Fetcher] Schedule å¼€å§‹è°ƒåº¦ä»»åŠ¡",
		slog.String("start_block", start.String()),
		slog.String("end_block", end.String()),
	)

	// ğŸ”¥ æ¨ªæ»¨å®éªŒå®¤ï¼šä¸Šæ¸¸èƒŒå‹æ£€æµ‹
	// æ£€æŸ¥ä¸‹æ¸¸æ°´ä½çº¿ï¼Œé¿å…æ— ç•Œè°ƒåº¦å¯¼è‡´èƒŒå‹
	jobsDepth := len(f.jobs)
	resultsDepth := len(f.Results)
	maxJobsCapacity := cap(f.jobs)
	maxResultsCapacity := cap(f.Results)

	// æ°´ä½çº¿é˜ˆå€¼
	jobsWatermark := maxJobsCapacity * 90 / 100       // 90%
	resultsWatermark := maxResultsCapacity * 90 / 100 // 90%

	if jobsDepth > jobsWatermark {
		Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Jobs queue too deep",
			slog.Int("jobs_depth", jobsDepth),
			slog.Int("jobs_watermark", jobsWatermark),
			slog.Int("jobs_capacity", maxJobsCapacity),
			slog.Int("results_depth", resultsDepth))
		return fmt.Errorf("fetcher jobs queue backpressure: depth=%d/%d", jobsDepth, maxJobsCapacity)
	}

	if resultsDepth > resultsWatermark {
		Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Results channel too deep",
			slog.Int("results_depth", resultsDepth),
			slog.Int("results_watermark", resultsWatermark),
			slog.Int("results_capacity", maxResultsCapacity),
			slog.Int("jobs_depth", jobsDepth))
		return fmt.Errorf("fetcher results channel backpressure: depth=%d/%d", resultsDepth, maxResultsCapacity)
	}

	// ğŸ”¥ æ£€æŸ¥ Sequencer buffer æ·±åº¦
	if f.sequencer != nil {
		seqBufferSize := f.sequencer.GetBufferSize()
		if seqBufferSize > 2000 {
			Logger.Warn("ğŸš« [Fetcher] SCHEDULE_BLOCKED: Sequencer buffer too deep",
				slog.Int("sequencer_buffer_size", seqBufferSize),
				slog.Int("jobs_depth", jobsDepth),
				slog.Int("results_depth", resultsDepth))
			return fmt.Errorf("sequencer buffer backpressure: size=%d", seqBufferSize)
		}
	}

	// å·¥ä¸šçº§å»ºè®®ï¼šRange æŸ¥è¯¢æ­¥é•¿
	// æ­£å¸¸åŒæ­¥ä½¿ç”¨ 50 ä¸ªå—ï¼ŒCatch-up æ—¶å¯ä»¥æ›´å¤§
	batchSize := big.NewInt(50)
	current := new(big.Int).Set(start)
	jobCount := 0

	for current.Cmp(end) <= 0 {
		batchEnd := new(big.Int).Add(current, batchSize)
		if batchEnd.Cmp(end) > 0 {
			batchEnd = new(big.Int).Set(end)
		}

		job := FetchJob{
			Start: new(big.Int).Set(current),
			End:   new(big.Int).Set(batchEnd),
		}

		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-f.stopCh:
			return fmt.Errorf("fetcher stopped")
		case f.jobs <- job:
			jobCount++
		}

		// ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹
		current = new(big.Int).Add(batchEnd, big.NewInt(1))
	}

	Logger.Info("ğŸ“‹ [Fetcher] Schedule å®Œæˆï¼Œæ‰€æœ‰ä»»åŠ¡å·²å‘é€",
		slog.Int("total_jobs", jobCount),
	)
	return nil
}
