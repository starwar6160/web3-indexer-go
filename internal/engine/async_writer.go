package engine

import (
	"context"
	"database/sql"
	"log/slog"
	"sync"
	"sync/atomic"
	"time"

	"web3-indexer-go/internal/models"

	"github.com/jmoiron/sqlx"
)

// ğŸ”¥ å·¥ä¸šçº§å¼‚æ­¥å†™å…¥å™¨ (AsyncWriter) - æ¨ªæ»¨å®éªŒå®¤ä¸“ç”¨ç‰ˆ
// é’ˆå¯¹ AMD 3800X + 128G RAM + 990 PRO æè‡´ä¼˜åŒ–
// æ ¸å¿ƒç­–ç•¥ï¼šæµ·é‡å†…å­˜ç¼“å†² + æ‰¹é‡äº‹åŠ¡ + ç©ºå—è¿‡æ»¤

// PersistTask æºå¸¦éœ€è¦è½ç›˜çš„åŸå§‹äº¤æ˜“æ•°æ®
type PersistTask struct {
	Height    uint64            // åŒºå—é«˜åº¦
	Block     models.Block      // åŒºå—å…ƒæ•°æ®
	Transfers []models.Transfer // æå–å‡ºçš„è½¬è´¦è®°å½•
	Sequence  uint64            // æ¶ˆæ¯åºåˆ—å· (ç”¨äºè¿½è¸ª)
}

// AsyncWriter è´Ÿè´£å¼‚æ­¥æŒä¹…åŒ–é€»è¾‘
type AsyncWriter struct {
	// 1. è¾“å…¥é€šé“ï¼š100,000 æ·±åº¦ç¼“å†²ï¼Œåˆ©ç”¨ 128G å†…å­˜å½»åº•æ¶ˆé™¤èƒŒå‹
	taskChan chan PersistTask

	db           *sqlx.DB
	orchestrator *Orchestrator

	// 2. æ‰¹å¤„ç†é…ç½®
	batchSize     int
	flushInterval time.Duration

	// çŠ¶æ€æ§åˆ¶
	ctx    context.Context
	cancel context.CancelFunc
	wg     sync.WaitGroup

	// æ€§èƒ½æŒ‡æ ‡ (åŸå­æ“ä½œ)
	diskWatermark atomic.Uint64
	writeDuration atomic.Int64 // çº³ç§’
}

// NewAsyncWriter åˆå§‹åŒ–
func NewAsyncWriter(db *sqlx.DB, o *Orchestrator) *AsyncWriter {
	ctx, cancel := context.WithCancel(context.Background())
	w := &AsyncWriter{
		// ğŸš€ 16G RAM è°ƒä¼˜ï¼šå°† 100,000 ä¸‹è°ƒè‡³ 5,000
		taskChan:      make(chan PersistTask, 5000),
		db:            db,
		orchestrator:  o,
		batchSize:     1000, // 990 PRO é¡ºåºå†™å…¥æœ€ä½³æ‰¹æ¬¡
		flushInterval: 500 * time.Millisecond,
		ctx:           ctx,
		cancel:        cancel,
	}
	return w
}

// Start å¯åŠ¨å†™å…¥ä¸»å¾ªç¯
func (w *AsyncWriter) Start() {
	slog.Info("ğŸ“ AsyncWriter: Engine Started",
		"buffer_cap", cap(w.taskChan),
		"batch_size", w.batchSize,
		"flush_interval", w.flushInterval)

	w.wg.Add(1)
	go w.run()
}

func (w *AsyncWriter) run() {
	defer w.wg.Done()

	batch := make([]PersistTask, 0, w.batchSize)
	ticker := time.NewTicker(w.flushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-w.ctx.Done():
			// ä¼˜é›…é€€å‡ºï¼šå¤„ç†å‰©ä½™ä»»åŠ¡
			if len(batch) > 0 {
				w.flush(batch)
			}
			return

		case task := <-w.taskChan:
			batch = append(batch, task)
			if len(batch) >= w.batchSize {
				w.flush(batch)
				batch = batch[:0]
			}

		case <-ticker.C:
			if len(batch) > 0 {
				w.flush(batch)
				batch = batch[:0]
			}
		}
	}
}

// flush æ‰§è¡Œæ‰¹é‡å†™å…¥äº‹åŠ¡
func (w *AsyncWriter) flush(batch []PersistTask) {
	if len(batch) == 0 {
		return
	}

	start := time.Now()
	// å¼€å¯é«˜æ€§èƒ½äº‹åŠ¡
	tx, err := w.db.BeginTxx(w.ctx, nil)
	if err != nil {
		slog.Error("ğŸ“ AsyncWriter: BeginTx failed", "err", err)
		return
	}
	defer tx.Rollback()

	var (
		maxHeight      uint64 = 0
		totalTransfers        = 0
		validBlocks           = 0
	)

	for _, task := range batch {
		if task.Height > maxHeight {
			maxHeight = task.Height
		}

		// ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šç©ºå—è¿‡æ»¤
		// åœ¨ Anvil ç¯å¢ƒä¸­ï¼Œ95% ä»¥ä¸Šçš„å—æ˜¯ç©ºçš„ã€‚è·³è¿‡è¿™äº›å—çš„ DB å†™å…¥å¯æå¤§æå‡æ€§èƒ½ã€‚
		if len(task.Transfers) == 0 {
			continue
		}

		validBlocks++
		totalTransfers += len(task.Transfers)

		// 1. å†™å…¥åŒºå—å…ƒæ•°æ®
		if _, err := tx.ExecContext(w.ctx,
			`INSERT INTO blocks (number, hash, parent_hash, timestamp, gas_limit, gas_used, transaction_count)
			 VALUES ($1, $2, $3, $4, $5, $6, $7)
			 ON CONFLICT (number) DO NOTHING`,
			task.Block.Number.String(), task.Block.Hash, task.Block.ParentHash,
			task.Block.Timestamp, task.Block.GasLimit, task.Block.GasUsed, task.Block.TransactionCount); err != nil {
			slog.Error("ğŸ“ AsyncWriter: Insert block failed", "height", task.Height, "err", err)
			return
		}

		// 2. æ‰¹é‡å†™å…¥è½¬è´¦è®°å½•
		for _, t := range task.Transfers {
			if _, err := tx.ExecContext(w.ctx,
				`INSERT INTO transfers (block_number, tx_hash, log_index, from_address, to_address, amount, token_address, symbol, activity_type)
				 VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
				 ON CONFLICT DO NOTHING`,
				t.BlockNumber.String(), t.TxHash, t.LogIndex, t.From, t.To, t.Amount.String(), t.TokenAddress, t.Symbol, t.Type); err != nil {
				slog.Error("ğŸ“ AsyncWriter: Insert transfer failed", "tx", t.TxHash, "err", err)
				return
			}
		}
	}

	// 3. æ›´æ–°åŒæ­¥æ£€æŸ¥ç‚¹ (SSOT ç‰©ç†ç¡®è®¤)
	if _, err := tx.ExecContext(w.ctx,
		`INSERT INTO sync_checkpoints (chain_id, last_synced_block)
		 VALUES (1, $1)
		 ON CONFLICT (chain_id) DO UPDATE SET
			last_synced_block = EXCLUDED.last_synced_block,
			updated_at = NOW()`,
		maxHeight); err != nil {
		slog.Error("ğŸ“ AsyncWriter: Update checkpoint failed", "err", err)
		return
	}

	// ğŸš€ Grafana å¯¹é½ï¼šæ›´æ–° sync_status è¡¨
	syncedBlock := int64(maxHeight)
	chainHeight := syncedBlock
	if metrics := GetMetrics(); metrics != nil {
		if h := metrics.lastChainHeight.Load(); h > 0 {
			chainHeight = h
		}
	}
	lag := chainHeight - syncedBlock
	if lag < 0 {
		lag = 0
	}

	if _, err := tx.ExecContext(w.ctx, `
		INSERT INTO sync_status (chain_id, last_synced_block, latest_block, sync_lag, status, updated_at)
		VALUES ($1, $2, $3, $4, 'syncing', NOW())
		ON CONFLICT (chain_id) DO UPDATE SET
			last_synced_block = EXCLUDED.last_synced_block,
			latest_block = EXCLUDED.latest_block,
			sync_lag = EXCLUDED.sync_lag,
			status = EXCLUDED.status,
			updated_at = EXCLUDED.updated_at
	`, 1, syncedBlock, chainHeight, lag); err != nil {
		slog.Warn("ğŸ“ AsyncWriter: Update sync_status failed", "err", err)
	}

	if err := tx.Commit(); err != nil {
		slog.Error("ğŸ“ AsyncWriter: Commit failed", "err", err)
		return
	}

	// æ›´æ–°ç£ç›˜æ°´ä½çº¿
	w.diskWatermark.Store(maxHeight)
	w.writeDuration.Store(int64(time.Since(start)))

	// --- 4. é—­ç¯é€šçŸ¥ (SSOT) ---
	// æ— è®ºæ˜¯å¦å†™å…¥äº†æ•°æ®åº“ï¼ˆç©ºå—ä¹Ÿç®—åŒæ­¥æˆåŠŸï¼‰ï¼Œéƒ½è¦é€šçŸ¥ Orchestrator
	// åªæœ‰æ”¶åˆ° CmdCommitDiskï¼ŒSyncedCursor æ‰ä¼šçœŸæ­£æ¨è¿›
	w.orchestrator.Dispatch(CmdCommitDisk, maxHeight)

	// æ€§èƒ½æ—¥å¿—
	dur := time.Since(start)
	if validBlocks > 0 || dur > 100*time.Millisecond {
		slog.Info("ğŸ“ AsyncWriter: Batch Flushed",
			"batch_len", len(batch),
			"valid_blocks", validBlocks,
			"transfers", totalTransfers,
			"tip", maxHeight,
			"dur", dur)
	}
}

// Enqueue æäº¤æŒä¹…åŒ–ä»»åŠ¡ (éé˜»å¡)
func (w *AsyncWriter) Enqueue(task PersistTask) error {
	select {
	case w.taskChan <- task:
		return nil
	default:
		return sql.ErrConnDone // ç®€å•è¡¨ç¤ºé˜Ÿåˆ—æ»¡ (å®é™…ä¸åº”å‘ç”Ÿ)
	}
}

// GetMetrics è·å–æ€§èƒ½æŒ‡æ ‡
func (w *AsyncWriter) GetMetrics() map[string]interface{} {
	return map[string]interface{}{
		"disk_watermark":    w.diskWatermark.Load(),
		"write_duration_ms": time.Duration(w.writeDuration.Load()).Milliseconds(),
		"queue_depth":       len(w.taskChan),
	}
}

// Shutdown ä¼˜é›…å…³é—­
func (w *AsyncWriter) Shutdown(timeout time.Duration) error {
	slog.Info("ğŸ“ AsyncWriter: Shutting down...")
	w.cancel()

	done := make(chan struct{})
	go func() {
		w.wg.Wait()
		close(done)
	}()

	select {
	case <-done:
		return nil
	case <-time.After(timeout):
		return context.DeadlineExceeded
	}
}
